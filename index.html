<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://annen-stack.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="annen&#39;s blog">
<meta property="og:url" content="https://annen-stack.github.io/index.html">
<meta property="og:site_name" content="annen&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="ah">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://annen-stack.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>annen's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">annen's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/02/08/%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B-%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%8F%91%E7%8E%B0%E7%BE%A4%E7%BB%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/08/%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B-%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%8F%91%E7%8E%B0%E7%BE%A4%E7%BB%84/" class="post-title-link" itemprop="url">集体智慧编程_第三章发现群组</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-08 15:16:26 / 修改时间：15:17:28" itemprop="dateCreated datePublished" datetime="2020-02-08T15:16:26+08:00">2020-02-08</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>本章对上一章中的思想加以扩展，并引入数据聚类的概念，这是一种用以寻找紧密相关的事、人或观点，并将其可视化的方法。</p>
</blockquote>
<h4 id="监督学习和无监督学习"><a href="#监督学习和无监督学习" class="headerlink" title="监督学习和无监督学习"></a>监督学习和无监督学习</h4><p>监督学习法：利用样本的输入和期望输出来学习如何预测的技术。包括神经网络、决策树、向量支持机，以及贝叶斯过滤。</p>
<p>无监督学习算法不是带有正确答案进行训练，目的是在一组数据中找寻某种结构，而这些数据本身不是我们所需要的答案。聚类算法的目标是采集数据，然后从中找出不同的分组。其他无监督学习的例子还包括非负矩阵因式分解和自组织映射。</p>
<h4 id="单词向量"><a href="#单词向量" class="headerlink" title="单词向量"></a>单词向量</h4><h5 id="对博客用户进行分类"><a href="#对博客用户进行分类" class="headerlink" title="对博客用户进行分类"></a>对博客用户进行分类</h5><p>在第一个数据集中，被用来聚类的是排名在前120位的一系列博客，为了对博客进行聚类，我们需要的是一组指定的词汇在每个博客订阅源中出现的次数。<br>根据单词出现的频率对博客进行聚类，或许可以帮助我们分析出是否存在这样一类博客用户，这些人经常撰写相似的主题。</p>
<h5 id="对订阅源中的单词进行计数"><a href="#对订阅源中的单词进行计数" class="headerlink" title="对订阅源中的单词进行计数"></a>对订阅源中的单词进行计数</h5><p>RSS订阅源是一个包含博客及其所有文章条目信息的简单的XML文档。为了给每个博客中的单词进行计数，首先第一就是解析这些订阅源。我们利用universal feed parser，从RSS订阅源中得到标题、链接和文章条目了。</p>
<p>下一步，我们编写从订阅源中提取所有单词的函数，新建一个名为generatefeedvector.py的文件，并加入以下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import feedparser</span><br><span class="line">import re</span><br><span class="line">#返回一个含订阅源的标题和包含单词个数情况的字典</span><br><span class="line">def getwordcounts(url):</span><br><span class="line">    #解析订阅源</span><br><span class="line">    d&#x3D;feedparser.parse(url)</span><br><span class="line">    wc&#x3D;&#123;&#125;#用来存储在文章中出现的单词和次数</span><br><span class="line">    for e in d.entries:</span><br><span class="line">        if &#39;summary&#39; in e: summary&#x3D;e.summary</span><br><span class="line">        else: summary&#x3D;e.description</span><br><span class="line">        #提取一个单词列表</span><br><span class="line">        #传入的是XML文件</span><br><span class="line">        words&#x3D;getwords(e.title+&#39;&#39;+summary)#摘要</span><br><span class="line">        for word in words:</span><br><span class="line">            wc.setdefault(word,0)</span><br><span class="line">            wc[word]+&#x3D;1</span><br><span class="line">    return d.feed.title,wc</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def getwords(html):</span><br><span class="line">    #去除所有html标记</span><br><span class="line">    txt&#x3D;re.compile(r&#39;&lt;[^&gt;]+&gt;&#39;).sub(&#39;&#39;,html)</span><br><span class="line">    #利用所有非字母字符拆分出单词</span><br><span class="line">    words&#x3D;re.compile(r&#39;[^A-Z^a-z]+&#39;).split(txt)</span><br><span class="line">    #转化成小写形式</span><br><span class="line">    return [word.lower() for word in words if word!&#x3D;&#39;&#39;]</span><br></pre></td></tr></table></figure>
<p>为了开始下一步的工作，我们需要一个订阅源列表。我们从此处下载到列表(<a href="http://kiwitobes.com/clusters/feedlist.txt)这是一个普通的文本文件，每一行对应一个url。" target="_blank" rel="noopener">http://kiwitobes.com/clusters/feedlist.txt)这是一个普通的文本文件，每一行对应一个url。</a></p>
<p>generatefeedvector.py文件中的主体代码循环遍历   订阅源并生成数据集。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">wordcounts&#x3D;&#123;&#125;#key:文章标题；value:单词以及单词数</span><br><span class="line">apcount&#x3D;&#123;&#125;#为出现这些单词的博客数目</span><br><span class="line">#feedurl表示遍历该文本文件的每一行，是个url文件</span><br><span class="line">feedlist&#x3D;[line for line in file(&#39;feedlist.txt&#39;)]</span><br><span class="line">for feedurl in feedlist:  </span><br><span class="line">    title,wc&#x3D;getwordcounts(feedurl)</span><br><span class="line">    #每个博客对应的字典</span><br><span class="line">    wordcounts[title]&#x3D;wc</span><br><span class="line">    for word,count in wc.items():</span><br><span class="line">        apcount.setdefault(word,0)</span><br><span class="line">        if count&gt;1:  #表示博客中有该单词</span><br><span class="line">           apcount[word]+&#x3D;1</span><br></pre></td></tr></table></figure>
<p>把上述代码添加到generatefeedvector.py文件中。接下来，我们对单词进行筛选，减少要考察的单词的总量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#只是添加所需要的单词</span><br><span class="line">wordlist&#x3D;[]</span><br><span class="line">#apcount的key为单词；value为该单词出现的博客数目</span><br><span class="line">for w,bc in apcount.items():</span><br><span class="line">    frac&#x3D;float(bc)&#x2F;len(feedlist)</span><br><span class="line">    if frac&gt;0.1 and frac&lt;0.5: wordlist.append(w)</span><br></pre></td></tr></table></figure>
<p>最后，我们对上述单词列表和博客列表来建立一个文本文件，包含一个大的矩阵，记录针对每个博客的所有单词的统计情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">out&#x3D;file(&#39;blogdata.txt&#39;,&#39;w&#39;)</span><br><span class="line">out.write(&#39;blog&#39;)</span><br><span class="line">for word in wordlist: out.write(&#39;\t%s&#39; %word)#单词的标题</span><br><span class="line">out.write(&#39;\n&#39;)</span><br><span class="line">for blog,wc in wordcounts.items():#blog为博客标题；wc为该博客中的单词及单词数，需要利用wordlist进行筛选</span><br><span class="line">   out.write(blog)#博客标题</span><br><span class="line">   for word in wordlist:</span><br><span class="line">       if word in wc:out.write(&#39;\t%d&#39;%wc[word])#输出该单词数</span><br><span class="line">       else:out.write(&#39;\t0&#39;)</span><br><span class="line">   #一个博客输出完后换行</span><br><span class="line">   out.write(&#39;\n&#39;)</span><br></pre></td></tr></table></figure>
<p>最后得到blogdata.txt文件</p>
<h4 id="分级聚类"><a href="#分级聚类" class="headerlink" title="分级聚类"></a>分级聚类</h4><p>通过连续不断的将最为相似的群组两两合并，来构造一个群组的层级结构。其中每个群组都是从单一元素开始的。在每次迭代过程中，分级聚类算法会计算每两个群组之间的距离，并将距离最近的两个群组合并在一起成一个新的群组。这个过程会持续下去直到只剩一个群组为止。我们也可以采用树状图来展示他们。</p>
<p>本节我们将示范如何对博客数据集进行聚类，以构造博客的层级结构；如果构造成功，我们将实现按主题对博客进行分组。首先我们需要一个方法来加载数据文件：</p>
<p><strong>在clusters.py文件中。</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def readfile(filename):</span><br><span class="line">   #lines表示该文件，若读取每一行则：for l in lines</span><br><span class="line">   lines&#x3D;[line for line in file(filename)]</span><br><span class="line">   #第一行为列标题</span><br><span class="line">   rownames&#x3D;[]#列表</span><br><span class="line">   data&#x3D;[]</span><br><span class="line">   colnames&#x3D;lines[0].strip().split(&#39;\t&#39;)[1:]</span><br><span class="line">   for line in lines[1:]:#从第二行开始读取</span><br><span class="line">      p&#x3D;line.strip().split(&#39;\t&#39;)#将每一行的数据按照空格分隔</span><br><span class="line">      #每行的第一列为行名</span><br><span class="line">      rownames.append(p[0])</span><br><span class="line">      data.append([float(x) for x in p[1:]])</span><br><span class="line">   return rownames,colnames,data</span><br></pre></td></tr></table></figure>
<p>data中的每一项对应数据集中的一行数据；rownames为每行的名字；colnames为每列的名字。</p>
<p>下一步我们来定义紧密度：<br>一些博客总体上比其他博客包含更多的文章条目。皮尔逊相关度可以纠正这一问题，因为他判断的是两组数据与某条直线的拟合程度。<br>在两组完全匹配的情况下，为1.0.毫无关系的情况下为0。<br>皮尔逊算法代码略<br>。</p>
<p>新建一个类，代表聚类的类型:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class bicluster:</span><br><span class="line">     def __init__(self,vec,left&#x3D;None,right&#x3D;None,distance&#x3D;0.0,id&#x3D;None)</span><br><span class="line">          self.left&#x3D;left</span><br><span class="line">          self.right&#x3D;right</span><br><span class="line">          self.vec&#x3D;vec</span><br><span class="line">          self.id&#x3D;id</span><br><span class="line">          self.distance&#x3D;distance</span><br></pre></td></tr></table></figure>
<p><strong>分级聚类算法</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def hcluster(rows,distance&#x3D;person):#rows为readfile中的data</span><br><span class="line">      distances&#x3D;&#123;&#125;</span><br><span class="line">      currentclustid&#x3D;-1</span><br><span class="line">      #最开始聚类的就是数据集中的行</span><br><span class="line">      clust&#x3D;[bicluster(row[i],id&#x3D;i) for i in range(len(rows))]</span><br><span class="line">      while len(clust)&gt;1:</span><br><span class="line">           lowestpair&#x3D;(0,1)</span><br><span class="line">           closest&#x3D;distance(clust[0].vec,clust[1].vec)</span><br><span class="line">           #遍历每个配对，寻找最小距离</span><br><span class="line">           for i in range(len(clust)):</span><br><span class="line">               for j in range(i+1,len(clust)):</span><br><span class="line">                     if (clust[i].id,clust[j].id) not in distances:</span><br><span class="line">                         distances[(clust[i].id,clust[j].id)]&#x3D;distance(clust[i].vec,clust[j].vec)</span><br><span class="line">                    d&#x3D;distances[(clust[i].id,clust[j].id)]#d为value；distances为字典</span><br><span class="line">                    if d&lt;closest:</span><br><span class="line">                         closest&#x3D;d</span><br><span class="line">                         lowersetpair&#x3D;(i,j)</span><br><span class="line">            #计算两个距离的平均值</span><br><span class="line">            mergevec&#x3D;[(clust[lowersetpair[0]].vec[i]+clust[lowersetpair[1]].vec[i])&#x2F;2 for i in range(len(clust[0].vec))]</span><br><span class="line">            #建立新的聚类</span><br><span class="line">            newcluster&#x3D;bicluster(mergevec,left&#x3D;clust[lowestpair[0]],right&#x3D;clust[lowestpair[1]],distance&#x3D;closet,id&#x3D;currentclustid&#x3D;-1)</span><br><span class="line">            currentclustid-&#x3D;1</span><br><span class="line">            del clust[lowestpair[1]]</span><br><span class="line">            del clust[lowestpair[0]]</span><br><span class="line">            clust.append(newcluster)</span><br><span class="line">        return clust[0]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import clusters</span><br><span class="line">blognames,words,data&#x3D;clusters.readfile(&#39;blogdata.txt&#39;)</span><br><span class="line">clust&#x3D;clusters.hcluster(data)</span><br><span class="line">clusters.printclust(clust,label&#x3D;blognames)</span><br></pre></td></tr></table></figure>
<p>打印聚类树</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def printclust(clust,labels&#x3D;None,n&#x3D;0):</span><br><span class="line">    #利用缩进来建立层次布局</span><br><span class="line">    for i in range(n):print &#39; &#39;,</span><br><span class="line">    if clust.id&lt;0:</span><br><span class="line">        #负数代表是一个分支</span><br><span class="line">        print&#39;-&#39;</span><br><span class="line">    else:</span><br><span class="line">        #正数代表是个叶节点</span><br><span class="line">        if labels&#x3D;None:print clust.id</span><br><span class="line">        else: print labels[clust.id]#打印博客名字</span><br><span class="line">    if clust.left!&#x3D;None: printclust(clust.left,labels&#x3D;labels,n&#x3D;n+1)</span><br><span class="line">    if clust.right!&#x3D;None: printclust(clust.right,labels&#x3D;labels,n&#x3D;n+1)</span><br></pre></td></tr></table></figure>
<h4 id="绘制树状图"><a href="#绘制树状图" class="headerlink" title="绘制树状图"></a>绘制树状图</h4><p>安装PIL，我利用的是anaconda整合好的<br><img src="D58E94581AD24FFDB486BC5D46052BCC" alt="image"></p>
<p>首先确定聚类的总体高度：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image,ImageDraw</span><br><span class="line">def getheight(clust):</span><br><span class="line">    if clust.left&#x3D;&#x3D;None and clust.right&#x3D;&#x3D;None: return 1</span><br><span class="line">    return getheight(clust.left)+getheight(clust.right)</span><br></pre></td></tr></table></figure>
<p>除此之外，我们还需要知道根节点的总体误差。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def getdepth(clust):</span><br><span class="line">    if clust.left&#x3D;&#x3D;None and clust.right&#x3D;&#x3D;None: return 0</span><br><span class="line">    return max(getdepth(clust.left),getdepth(clust.right))+clust.distance</span><br></pre></td></tr></table></figure>
<p>函数drawdendrogram为每个生成的聚类创建一个高度为20像素、宽度固定的图片。</p>
<p>略</p>
<h4 id="列聚类"><a href="#列聚类" class="headerlink" title="列聚类"></a>列聚类</h4><p>之前的算法是对博客类型进行聚类，处理的是博客。现在我们将data矩阵倒置，对单词类型进行聚类。<br>倒置函数：将行和列对调。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def rotatematrix(data):</span><br><span class="line">    newdata&#x3D;[]</span><br><span class="line">    for i in range(len(data[0])):</span><br><span class="line">        newrow&#x3D;[data[j][i] for j in range(len(data))]</span><br><span class="line">        newdata.append(newrow)</span><br><span class="line">    return newdata</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import clusters</span><br><span class="line">blognames,words,data&#x3D;clusters.readfile(&#39;blogdata.txt&#39;)</span><br><span class="line">rdata&#x3D;clusters.rotatematrix(data)</span><br><span class="line">wordclust&#x3D;clusters.hcluster(rdata)</span><br><span class="line">clusters.drawdendrogram(wordclust,labels&#x3D;words,jpeg&#x3D;&#39;wordclust.jpg&#39;)</span><br></pre></td></tr></table></figure>

<h4 id="K-均值聚类"><a href="#K-均值聚类" class="headerlink" title="K-均值聚类"></a>K-均值聚类</h4><p>首先确定K个中心位置，然后将各个数据项分配到最邻近的中心点。待分配完成后，聚类中心更新到所有节点的平均位置处。然后整个分配过程重新开始。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">def kcluster(rows,distance&#x3D;pearson,k&#x3D;4)</span><br><span class="line">   #确定每列的最大值和最小值,每行为一个点</span><br><span class="line">   ranges&#x3D;[(min([row[i] for row in rows]),max([row[i] for row in rows])) for i in range(len(rows[0]))]</span><br><span class="line">   #随机创建k个中心点，每个点为一列数</span><br><span class="line">   clusters&#x3D;[[random.random()*(ranges[i][1]-ranges[i][0])+ranges[i][0] for i in range(len(rows[0]))]for j in range(k)]</span><br><span class="line">   </span><br><span class="line">   lastmatches&#x3D;None</span><br><span class="line">   for t in range(100):#迭代次数</span><br><span class="line">       print &#39;iteration %d&#39; % t</span><br><span class="line">       bestmatches&#x3D;[[] for i in range(k)]</span><br><span class="line">       #在每行中寻找最近的中心点</span><br><span class="line">       for j in range(len(rows)):</span><br><span class="line">       #第j行</span><br><span class="line">            row&#x3D;rows[j]</span><br><span class="line">            bestmatch&#x3D;0</span><br><span class="line">            for i in range(k):</span><br><span class="line">               d&#x3D;distance(clusters[i],row)</span><br><span class="line">               if d&lt;distance(clusters[bestmatch],row):bestmatch&#x3D;i</span><br><span class="line">            bestmatches[bestmatch].append(j)</span><br><span class="line">            #直到所有行都确定了最近的中心点</span><br><span class="line">        if bestmatches&#x3D;&#x3D;lastmatches:break</span><br><span class="line">        lastmatches&#x3D;bestmatches</span><br><span class="line">        #把中心点移到所有成员的平均位置处</span><br><span class="line">        for i in range(k):</span><br><span class="line">            avgs&#x3D;[0.0]*len(rows[0])</span><br><span class="line">            if(len(bestmatches[i])&gt;0:</span><br><span class="line">                for rowid in bestmatches[i]:</span><br><span class="line">                    for m in range(len(rows[rowid]))</span><br><span class="line">                       avgs[m]+&#x3D;rows[rowid][m]</span><br><span class="line">                for j in range(len(avgs)):</span><br><span class="line">                    avgs[j]&#x2F;&#x3D;len(bestmatches[i])</span><br><span class="line">                clusters[i]&#x3D;avgs</span><br><span class="line">    return bestmatches</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">reload(clusters)</span><br><span class="line">blognames,words,data&#x3D;clusters.readfile(&#39;blogdata.txt&#39;)</span><br><span class="line">kclust&#x3D;clusters.kclusters(data,k&#x3D;10)</span><br><span class="line">#分成了k&#x3D;0,1,...9类别，输出同类别的电影名</span><br><span class="line">[blognames[r] for r in kclust[0]]</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/02/07/%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B-%E7%AC%AC%E4%BA%8C%E7%AB%A0%E6%8F%90%E4%BE%9B%E6%8E%A8%E8%8D%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/07/%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B-%E7%AC%AC%E4%BA%8C%E7%AB%A0%E6%8F%90%E4%BE%9B%E6%8E%A8%E8%8D%90/" class="post-title-link" itemprop="url">集体智慧编程_第二章提供推荐</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-07 22:04:59 / 修改时间：22:06:09" itemprop="dateCreated datePublished" datetime="2020-02-07T22:04:59+08:00">2020-02-07</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="协作型推荐"><a href="#协作型推荐" class="headerlink" title="协作型推荐"></a>协作型推荐</h3><p>一个协作型过滤算法是对一大群人进行搜索，并从中找出与我们品味相近的小群人。算法会对这些人所偏爱的其他内容进行考察，并将他们组合起来构造出一个经过排名的推荐列表。</p>
<h3 id="搜集偏好"><a href="#搜集偏好" class="headerlink" title="搜集偏好"></a>搜集偏好</h3><p>我们通过采用嵌套的字典的方法来表达不同人及其偏好的方法。</p>
<p>我们建立一个数据集,命名为recommendations.py 采用1到5的评分，来体现包括本人在内的每位影评者对某给定影片的喜爱程度。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from recommendations import critics</span><br><span class="line">critics[&#39;Lisa Rose&#39;][&#39;Lady in the Water&#39;]</span><br><span class="line">#输出Lisa Rose对Lady in the water这部电影的评分。</span><br></pre></td></tr></table></figure>
<h3 id="寻找相近的用户"><a href="#寻找相近的用户" class="headerlink" title="寻找相近的用户"></a>寻找相近的用户</h3><p>在搜集完人们的偏好后，即建立数据集后，我们需要一种方法来确定人民在品味中的相似程度。我们可以将每个人与所有其他人进行对比，并计算他们的相似度评价值。</p>
<h5 id="欧几里得距离评价"><a href="#欧几里得距离评价" class="headerlink" title="欧几里得距离评价"></a>欧几里得距离评价</h5><p>1/(1+sqrt(pow(x1-x2,2)+pow(y1-y2,2)))</p>
<p>上述值越大，表示越相似。</p>
<p>prefs表示数据集名称；person1表示数据集中的key;item表示下一级电影名称；prefs[preson1][item]表示分数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from math import sqrt</span><br><span class="line">#返回一个有关person1与person2的基于距离的相似度评价</span><br><span class="line">def sim_distance(prefs,person1,person2):</span><br><span class="line">    si&#x3D;&#123;&#125;</span><br><span class="line">    for item in prefs[person1]:</span><br><span class="line">        if item in prefs[person2]:  #表示两个人都有电影重合</span><br><span class="line">           si[item]&#x3D;1 #item是key;1是value</span><br><span class="line">    if len(si)&#x3D;&#x3D;0:</span><br><span class="line">        return 0</span><br><span class="line">    #计算两个人中重合的电影中评分的差值的平方和</span><br><span class="line">    sum_of_squares&#x3D;sum([pow(prefs[person1][item]-prefs[preson2][item],2) for item in prefs[person1] if item in prefs[person2]])</span><br><span class="line">    return 1&#x2F;(sqrt(sum_of_squares)+1)</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reload(recommendations)</span><br><span class="line">recommendations.sim_distance(recommendations.critics,&#39;Lisa Rose&#39;,&#39;Gene Seymour&#39;)</span><br><span class="line">#输出相似度数字</span><br></pre></td></tr></table></figure>
<h5 id="皮尔逊相关度评价"><a href="#皮尔逊相关度评价" class="headerlink" title="皮尔逊相关度评价"></a>皮尔逊相关度评价</h5><p>该相关系数是判断两组数据与某一直线拟合程度的一种度量，在数据不是很规范的情况下，会倾向给出更好的结果。<br>它可修正夸大分值的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from math import sqrt</span><br><span class="line">#返回一个有关person1与person2的基于距离的相似度评价</span><br><span class="line">def sim_person(prefs,p1,p2):</span><br><span class="line">    si&#x3D;&#123;&#125;</span><br><span class="line">    for it in prefs[p1]:</span><br><span class="line">        if it in prefs[p2]:  #表示两个人都有电影重合</span><br><span class="line">           si[it]&#x3D;1 #item是key;1是value</span><br><span class="line">    if len(si)&#x3D;&#x3D;0:</span><br><span class="line">        return 0</span><br><span class="line">    #对所有偏好进行求和</span><br><span class="line">    sum1&#x3D;sum([prefs[p1][it] for it in si])</span><br><span class="line">    sum2&#x3D;sum([prefs[p2][it] for it in si])</span><br><span class="line">    #求平方和</span><br><span class="line">    sum1sq&#x3D;sum([pow(prefs[p1][it],2) for it in si])</span><br><span class="line">    sum2sq&#x3D;sum([pow(prefs[p2][it],2) for it in si])</span><br><span class="line">    #求乘积和</span><br><span class="line">    psum&#x3D;sum([prefs[p1][it]*prefs[p2][it] for it in si])</span><br><span class="line">    #计算皮尔逊评价值</span><br><span class="line">    num&#x3D;psum-(sum1*sum2&#x2F;n)</span><br><span class="line">    den&#x3D;sqrt((sum1sq-pow(sum1,2)&#x2F;n)*(sum2sq-pow(sum2,2)&#x2F;n))</span><br><span class="line">    if den&#x3D;&#x3D;0:</span><br><span class="line">       return 0</span><br><span class="line">    r &#x3D; num&#x2F;den</span><br><span class="line">    </span><br><span class="line">    return r</span><br></pre></td></tr></table></figure>
<h4 id="为评论者打分"><a href="#为评论者打分" class="headerlink" title="为评论者打分"></a>为评论者打分</h4><p>我们将下列函数加入recommendation.py中，以得到一个人员的有序列表，这些人与某个指定人员具有相似的品味。</p>
<p>prefs为数据集；person为某个指定人员；similarity为某个相似度函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def topmatches(prefs,person,n&#x3D;5,similarity&#x3D;sim_person):</span><br><span class="line">#将指定人员与数据中除自己外的所有人员一一比较，记录相似度值。</span><br><span class="line">    scores &#x3D; [(similarity(prefs[person],other),other) for other in prefs for other in prefs if other !&#x3D; person]</span><br><span class="line">    #评价最高者排在最前面</span><br><span class="line">    scores.sort()</span><br><span class="line">    scores.reverse()</span><br><span class="line">    return scores[0:n]  #输出前三个数</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#topmatches为函数；critics为数据集；recommendations.py为函数</span><br><span class="line">reload(recommendations)</span><br><span class="line">recommendations.topmatches(recommendations.critics,&#39;Toby&#39;,n&#x3D;3)</span><br></pre></td></tr></table></figure>

<p>输出的是与目标人员兴趣最相近的其他人员。</p>
<h4 id="推荐物品"><a href="#推荐物品" class="headerlink" title="推荐物品"></a>推荐物品</h4><p>如果我们利用为评论者打分算法，得到口味最相近的其他人，在他的电影清单中选择，未免有点随意。本部分之间推荐与目标人员兴趣匹配的最佳电影。输出的是电影。 我们利用数据集，得到所有其他评论者与指定人员的相似度之后，再用相似度乘以他们对每部影片的评分，再把加权后的每部影片相加，除以相似度之和，对最终数据从高到低排序，得到最终的推荐影片排序。</p>
<p>与topmatches对比，输出不同。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#利用所有其他人评价值的加权平均，为某人提供建议</span><br><span class="line">def getrecommendations(prefs,person,similarity&#x3D;sim_person)</span><br><span class="line">    totals&#x3D;&#123;&#125;#为每部影片的加权后的总和</span><br><span class="line">    simsums&#x3D;&#123;&#125;#为其他人相似度的总和</span><br><span class="line">    #prefs为数据集</span><br><span class="line">    for other in prefs:</span><br><span class="line">       #不和自己做比较,person为指定人员</span><br><span class="line">       if other&#x3D;&#x3D;person:continue</span><br><span class="line">       sim&#x3D;similarity(prefs,person,other)#sim为相似度</span><br><span class="line">       #忽略评价值为零或小于零的情况</span><br><span class="line">       if sim&lt;&#x3D;0:continue</span><br><span class="line">       #item为电影</span><br><span class="line">       for item in prefs[other]:</span><br><span class="line">            if item not in prefs[person] or prefs[person][item]&#x3D;&#x3D;0:</span><br><span class="line">                totals.setdefault(item,0)</span><br><span class="line">                total[item]+&#x3D;prefs[other][item]*sim</span><br><span class="line">                simsums.setdefault(item,0)</span><br><span class="line">                simsums[item]+&#x3D;sim</span><br><span class="line">   ranking&#x3D;[(total&#x2F;simsums[item],item) for item,total in totals.items()]</span><br><span class="line">   </span><br><span class="line">   ranking.sort()</span><br><span class="line">   ranking.reverse()</span><br><span class="line">   return ranking</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reload(recommendations)</span><br><span class="line">recommendations.getcommendations(recommendations.critics,&#39;Toby&#39;)</span><br></pre></td></tr></table></figure>
<p>输出的是推荐的相似度高的电影。</p>
<h4 id="匹配商品-人与物交换"><a href="#匹配商品-人与物交换" class="headerlink" title="匹配商品(人与物交换)"></a>匹配商品(人与物交换)</h4><p>假如我们想了解哪些产品是相近的呢？在这种情况下，我们可以通过哪些人喜欢某一特定物品，以及这些喜欢哪些其他物品来决定相似度。即我们把之前的例子，人与物品互换即可。</p>
<p>人与物品互换</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def transformprefs(prefs):  #prefs为数据集</span><br><span class="line">    result&#x3D;&#123;&#125;  #result为与prefs类似的数据集</span><br><span class="line">    for person in prefs:</span><br><span class="line">        for item in prefs[person]:</span><br><span class="line">             result.setdefault(item,&#123;&#125;)</span><br><span class="line">             result[item][person]&#x3D;prefs[person][item]</span><br><span class="line">    return result#新的数据集</span><br></pre></td></tr></table></figure>
<p>获取与《superman returns》最类似的电影</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reload(recommendations)</span><br><span class="line">#movies为新的数据集</span><br><span class="line">movies&#x3D;recomms.transformprefs(recommendations.critics)</span><br><span class="line">recommendations.topmatches(movies,&#39;superman returns&#39;)</span><br></pre></td></tr></table></figure>
<p>我们还可以为该影片推荐评论者，或许我们考虑要求某人参加该电影的首映礼。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reload(recommendations)</span><br><span class="line">#movies为新的数据集</span><br><span class="line">movies&#x3D;recomms.transformprefs(recommendations.critics)</span><br><span class="line">recommendations.getrecommendations(movies,&#39;superman returns&#39;)</span><br></pre></td></tr></table></figure>

<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>在线零售商可以收集{person:{item1,item2}},将商品和人对调，可以帮助他们找到购买某个商品的潜在用户。此外，在专门推荐链接的网站上，可以确保新出现的链接，能够被那些最有可能对它产生兴趣的用户找到。</p>
<h4 id="构建一个基于del-icio-us的链接推荐系统"><a href="#构建一个基于del-icio-us的链接推荐系统" class="headerlink" title="构建一个基于del.icio.us的链接推荐系统"></a>构建一个基于del.icio.us的链接推荐系统</h4><p>本节将介绍，如何从最受欢迎的在线书签网站上获取数据，如何利用这些数据查找相近的用户，并向他们推荐一起未曾看过的链接。</p>
<p>但是这个API已经失效了！！<br>故放弃</p>
<h4 id="使用MOVIELENS数据集做推荐"><a href="#使用MOVIELENS数据集做推荐" class="headerlink" title="使用MOVIELENS数据集做推荐"></a>使用MOVIELENS数据集做推荐</h4><p>  下载MovieLens的地址：<a href="http://grouplens.org/datasets/movielens/" target="_blank" rel="noopener">http://grouplens.org/datasets/movielens/</a>  </p>
<p>  数据集中的格式为：用户ID、影片ID、用户对该片的评分、评价时间</p>
<p>  加载数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def loadMovieLensTrain(filename&#x3D;&#39;u1.base&#39;):</span><br><span class="line"></span><br><span class="line">    str1 &#x3D;&#39;.&#x2F;ml-100k&#x2F;&#39;     </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    #加载数据</span><br><span class="line"></span><br><span class="line">    prefs&#x3D;&#123;&#125;</span><br><span class="line"></span><br><span class="line">    for line in open(str1+filename,&#39;r&#39;):</span><br><span class="line"></span><br><span class="line">        (user,movieid,rating,ts)&#x3D;line.split(&#39;\t&#39;)</span><br><span class="line"></span><br><span class="line">        prefs.setdefault(user,&#123;&#125;)</span><br><span class="line"></span><br><span class="line">        prefs[user][movieid]&#x3D;float(rating)</span><br><span class="line"></span><br><span class="line">    return prefs</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">def loadMovieLensTest(filename&#x3D;&#39;u1.test&#39;):                      </span><br><span class="line"></span><br><span class="line">    str1 &#x3D;&#39;.&#x2F;ml-100k&#x2F;&#39;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    #加载数据</span><br><span class="line"></span><br><span class="line">    prefs&#x3D;&#123;&#125;</span><br><span class="line"></span><br><span class="line">    for line in open(str1+filename,&#39;r&#39;):</span><br><span class="line"></span><br><span class="line">        (user,movieid,rating,ts)&#x3D;line.split(&#39;\t&#39;)</span><br><span class="line"></span><br><span class="line">        prefs.setdefault(user,&#123;&#125;)</span><br><span class="line"></span><br><span class="line">        prefs[user][movieid]&#x3D;float(rating)</span><br><span class="line"></span><br><span class="line">    return prefs             </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">if __name__&#x3D;&#x3D;&quot;__main__&quot;:</span><br><span class="line"></span><br><span class="line">    print (&quot;&quot;&quot;这个部分可以进行上面2个函数测试&quot;&quot;&quot;)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    trainDict&#x3D; loadMovieLensTrain()</span><br><span class="line"></span><br><span class="line">    testDict &#x3D; loadMovieLensTest()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    print (len(trainDict))</span><br><span class="line"></span><br><span class="line">    print (len(testDict))</span><br><span class="line"></span><br><span class="line">    print (&quot;&quot;&quot;测试通过&quot;&quot;&quot;)</span><br></pre></td></tr></table></figure>
<p>在该数据集中，建立字典，key为用户，value为电影和评分，与之前的critics数据集类似。</p>
<p><a href="https://blog.csdn.net/luzuiwutong/article/details/42718375" target="_blank" rel="noopener">参考链接</a></p>
<p>测试结果如下：<br>2为用户ID；306为某个电影ID;4.0为该电影的评分<br><img src="FECD665D69B741648ECD1B0B35D71D16" alt="image"><br>为用户28号推荐电影前20部<br><img src="FF37059EE8AB4593901CACED812E8747" alt="image"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/02/05/Implementing-Recurrent-Neural-Network-from-Scratch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/05/Implementing-Recurrent-Neural-Network-from-Scratch/" class="post-title-link" itemprop="url">Implementing Recurrent Neural Network from Scratch </a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-05 07:11:48 / 修改时间：07:38:59" itemprop="dateCreated datePublished" datetime="2020-02-05T07:11:48+08:00">2020-02-05</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a href="https://github.com/pangolulu/rnn-from-scratch" target="_blank" rel="noopener">Implementing Recurrent Neural Network from Scratch</a><br><img src="E1005AF131584DCF92EE6F2DDDEC316B" alt="2"><br><img src="EA04062A53C340DDB36F56245668566C" alt="草稿-3"><br><img src="5FE421509C9649D382385B7C079807B2" alt="草稿-4"><br><img src="27F66B26BFFC4E0A8E325A8F7B97D73E" alt="草稿-5"><br><img src="38FEA3EF46014D14B67B4F30D1BEAA4E" alt="草稿-6"><br><img src="725497E49B3644FAA316F103787E730B" alt="草稿-7"><br><img src="AB2D1AFE7E774376B5EB64A2A1BF33BF" alt="草稿-8"><br><img src="806CDBB1EA9442D4827F373CEA9D1E28" alt="草稿-9"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/02/04/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E9%83%A8%E5%88%86%E4%BB%A3%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/04/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E9%83%A8%E5%88%86%E4%BB%A3%E7%A0%81/" class="post-title-link" itemprop="url">数据预处理部分代码</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-04 17:46:04 / 修改时间：17:46:32" itemprop="dateCreated datePublished" datetime="2020-02-04T17:46:04+08:00">2020-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-文本格式数据读写"><a href="#1-文本格式数据读写" class="headerlink" title="1.文本格式数据读写"></a>1.文本格式数据读写</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df&#x3D;pd.read.csv(&#39;examples&#x2F;ex1.csv&#39;)</span><br></pre></td></tr></table></figure>
<h5 id="添加表头"><a href="#添加表头" class="headerlink" title="添加表头"></a>添加表头</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df&#x3D;pd.read.csv(&#39;examples&#x2F;ex1.csv&#39;，names&#x3D;[&#39;a&#39;,&#39;b&#39;],index_col&#x3D;&#39;message&#39;)</span><br></pre></td></tr></table></figure>
<h5 id="传入一个分层索引"><a href="#传入一个分层索引" class="headerlink" title="传入一个分层索引"></a>传入一个分层索引</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df&#x3D;pd.read.csv(&#39;examples&#x2F;ex1.csv&#39;，index_col&#x3D;[&#39;key1&#39;,&#39;key2&#39;])</span><br></pre></td></tr></table></figure>
<p>当字段是以多种不同数量的空格符分开时，可以传入正则表达式作为分隔符</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df&#x3D;pd.read.csv(&#39;examples&#x2F;ex1.csv&#39;，seq&#x3D;&#39;\s+&#39;)</span><br></pre></td></tr></table></figure>
<p>使用skiprows来跳过0，2，3行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df&#x3D;pd.read.csv(&#39;examples&#x2F;ex1.csv&#39;，skiprows&#x3D;[0,2,3])</span><br></pre></td></tr></table></figure>
<h5 id="分块读入文本文件"><a href="#分块读入文本文件" class="headerlink" title="分块读入文本文件"></a>分块读入文本文件</h5><p>在尝试大文件前，先进行设置使之更为紧凑</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.options.display.max_rows&#x3D;10</span><br></pre></td></tr></table></figure>
<p>分块读取文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chunker&#x3D;df&#x3D;pd.read.csv(&#39;examples&#x2F;ex1.csv&#39;，chunksize&#x3D;1000)</span><br><span class="line">tot&#x3D;pd.Series([])</span><br><span class="line">for piece in chunker:</span><br><span class="line">     tot&#x3D;tot.add(piece[&#39;key&#39;].value_counts(),fill_value&#x3D;0)</span><br><span class="line">tot&#x3D;tot.sort_values(ascending&#x3D;False)</span><br></pre></td></tr></table></figure>

<h3 id="2-数据清洗与准备"><a href="#2-数据清洗与准备" class="headerlink" title="2.数据清洗与准备"></a>2.数据清洗与准备</h3><h4 id="2-1处理缺失值"><a href="#2-1处理缺失值" class="headerlink" title="2.1处理缺失值"></a>2.1处理缺失值</h4><h5 id="2-1-1过滤缺失值"><a href="#2-1-1过滤缺失值" class="headerlink" title="2.1.1过滤缺失值"></a>2.1.1过滤缺失值</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from numpy import nan as NA</span><br><span class="line">data &#x3D; pd.Series([1,NA,3.5,NA,7])</span><br><span class="line">data.dropna()  #过滤掉缺失值</span><br></pre></td></tr></table></figure>
<p>data.dropna()会删掉包括缺失值的行</p>
<p>data.dropna(how=’all’) 仅会删除所有制均为NA的行</p>
<p>如果要删除列，则data.dropna(axis=1,how=’all’)</p>
<p>对矩阵进行重新赋值，利用iloc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df&#x3D;pd.DataFrame(np.random.randn(7,3))</span><br><span class="line">df.iloc[:4,1]&#x3D;NA  #前四行，第二列</span><br><span class="line">df.dropna(thresh&#x3D;2)</span><br></pre></td></tr></table></figure>
<h5 id="2-1-2补全缺失值"><a href="#2-1-2补全缺失值" class="headerlink" title="2.1.2补全缺失值"></a>2.1.2补全缺失值</h5><p>主要使用fillna方法来补全缺失值，可以使用一个常数来代替缺失值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.fillna(0)</span><br></pre></td></tr></table></figure>
<p>在调用fillna时，使用字典，可以为不同的列设置不同的填充值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.fillna(&#123;1:0.5,2:0&#125;)</span><br></pre></td></tr></table></figure>
<p>利用均值来填充</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.fillna(df.mean())</span><br></pre></td></tr></table></figure>
<h4 id="2-2数据转换"><a href="#2-2数据转换" class="headerlink" title="2.2数据转换"></a>2.2数据转换</h4><p>替代值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data&#x3D;pd.Series([1.,-999.,2.,-999.,-1000.,3.])</span><br><span class="line">data.replace(-999,np.nan)</span><br><span class="line">data.replace([-999,-1000],np.nan)</span><br><span class="line">#将不同的值替换成不同的值</span><br><span class="line">data.replace([-999,-1000],[np.nan,0])</span><br></pre></td></tr></table></figure>
<p>离散化和分箱</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">age&#x3D;[...]</span><br><span class="line">bin&#x3D;[1,2,3,4,5,6]</span><br><span class="line">cats&#x3D;pd.cut(age,bin)</span><br></pre></td></tr></table></figure>
<p>检测和过滤异常值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data&#x3D;pd.DataFrame(np.random.randn(1000,4))</span><br><span class="line">data.describe()</span><br></pre></td></tr></table></figure>
<p>假设要找出某一列中绝对值大于三的值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">col&#x3D;data[2]</span><br><span class="line">col[np.abs(col)&gt;3]</span><br></pre></td></tr></table></figure>
<p>要选出所有值绝对值大于三，可以使用any方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[(np.abs(data)&gt;3).any(1)]</span><br></pre></td></tr></table></figure>
<p>下面代码限制了-3到3之间的数值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data[np.abs(data)&gt;3]&#x3D;np.sign(data)*3</span><br><span class="line">+1&#x2F;-1</span><br></pre></td></tr></table></figure>














      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/02/04/%E9%81%A5%E6%B5%8B%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/04/%E9%81%A5%E6%B5%8B%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/" class="post-title-link" itemprop="url">遥测数据之数据预处理方法整理</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-04 17:40:29 / 修改时间：17:41:08" itemprop="dateCreated datePublished" datetime="2020-02-04T17:40:29+08:00">2020-02-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>数据清洗主要分为三步：<br>1.重复值处理——删除（有几个相同就删除还是全部得相同）<br>2.缺失值处理——删除，填充（均值，众数，中位数，前后相邻值），插值（拉格朗日插值，牛顿插值）<br>3.异常值处理——describe进行描述性分析+散点图+箱型图定位异常值，处理方法：删除，视为缺失值。</p>
</blockquote>
<p> 数据输入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">detail &#x3D; pd.read_csv(&quot;D:\\codes\\python\\data\\detail.csv&quot;,index_col&#x3D;0,encoding&#x3D;&#39;gbk&#39;)</span><br><span class="line">print(&#39;这个么去重前的样本形状：&#39;,detail.shape)</span><br></pre></td></tr></table></figure>

<p>去重：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">detail.drop_duplicates(inplace&#x3D;True)</span><br></pre></td></tr></table></figure>

<h3 id="一、数据清理"><a href="#一、数据清理" class="headerlink" title="一、数据清理"></a>一、数据清理</h3><p>数据清理主要通过填补缺失值、光滑噪声数据、平滑或删除离群点，并解决数据的不一致性来清理数据。</p>
<h4 id="1-缺失值处理"><a href="#1-缺失值处理" class="headerlink" title="1.缺失值处理"></a>1.缺失值处理</h4><ul>
<li>删除变量</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from numpy import nan as NA</span><br><span class="line">data &#x3D; pd.Series([1,NA,3.5,NA,7])</span><br><span class="line">data.dropna()  #过滤掉缺失值</span><br></pre></td></tr></table></figure>
<p>data.dropna()会删掉包括缺失值的行</p>
<p>data.dropna(how=’all’) 仅会删除所有制均为NA的行</p>
<p>如果要删除列，则data.dropna(axis=1,how=’all’)</p>
<p>对矩阵进行重新赋值，利用iloc</p>
<ul>
<li>均值填充</li>
</ul>
<p>主要使用fillna方法来补全缺失值，可以使用一个常数来代替缺失值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.fillna(0)</span><br></pre></td></tr></table></figure>
<p>在调用fillna时，使用字典，可以为不同的列设置不同的填充值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.fillna(&#123;1:0.5,2:0&#125;)</span><br></pre></td></tr></table></figure>
<p>利用均值来填充</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.fillna(df.mean())</span><br></pre></td></tr></table></figure>
<ul>
<li>哑变量填充<br>：变量为离散值</li>
<li>插值法补充</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">from scipy.interpolate import interp1d</span><br><span class="line">import numpy as np</span><br><span class="line">x&#x3D;np.array([1,2,3,4,5,8,9])</span><br><span class="line">y1&#x3D;np.array([2,8,18,32,50,128,162]) ##y1&#x3D;2*x^2</span><br><span class="line">y2&#x3D;np.array([3,5,7,9,11,17,19])  ##y2&#x3D;2*x+1</span><br><span class="line"></span><br><span class="line"># 线性插补</span><br><span class="line">linearinsvalue1&#x3D;interp1d(x,y1,kind&#x3D;&#39;linear&#39;)</span><br><span class="line">linearinsvalue2&#x3D;interp1d(x,y2,kind&#x3D;&#39;linear&#39;)</span><br><span class="line">print(linearinsvalue1([7,11]),linearinsvalue2([7,11]))</span><br><span class="line"></span><br><span class="line">out:[102. 246.] [15. 23.]</span><br><span class="line"></span><br><span class="line"># 拉格朗日插补</span><br><span class="line">from scipy.interpolate import lagrange</span><br><span class="line">largeinsvalue1&#x3D;lagrange(x,y1)</span><br><span class="line">largeinsvalue2&#x3D;lagrange(x,y2)</span><br><span class="line">print(largeinsvalue1([7,11]),largeinsvalue2([7,11]))</span><br><span class="line">out:[ 98. 242.] [15. 23.]</span><br><span class="line"></span><br><span class="line">#样条插补</span><br><span class="line">from scipy.interpolate import spline</span><br><span class="line">splineinsvalue1&#x3D;spline(x,y1,xnew&#x3D;np.array([7,11]))</span><br><span class="line">splineinsvalue2&#x3D;spline(x,y2,xnew&#x3D;np.array([7,11]))</span><br><span class="line">print(splineinsvalue1,splineinsvalue2)</span><br><span class="line">out:[ 98. 242.] [15. 23.]</span><br></pre></td></tr></table></figure>
<h4 id="2-离群点处理"><a href="#2-离群点处理" class="headerlink" title="2.离群点处理"></a>2.离群点处理</h4><p>异常值为处于特定分布区域或范围外的数据通常被定义为异常或噪声。</p>
<ul>
<li>简单统计分析：根据箱线图、各分位点判断是否出现异常<br>例如pd.describe可以迅速发现异常值</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.describe()</span><br></pre></td></tr></table></figure>
<p>可以画散点图观察</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">plt.scatter(data[&quot;数量&quot;],data[&quot;销售量&quot;])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>基于箱型图观察：四分位距(IQR)就是上四分位与下四分位的差值。而我们通过IQR的1.5倍为标准，规定：超过上四分位+1.5倍IQR距离，或者下四分位-1.5倍IQR距离的点为异常值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.subplot(1,2,1)</span><br><span class="line">plt.boxplot(data[&quot;数量&quot;])</span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">plt.boxplot(data[&quot; 销售金额 &quot;])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h5 id="异常值处理："><a href="#异常值处理：" class="headerlink" title="异常值处理："></a>异常值处理：</h5><p>1.删除—-先将异常值替换为na，然后用dropna（）删除</p>
<p>2.视为缺失值—-先将异常值替换为na,然后用缺失值处理方法处理（填充、插值等）</p>
<ul>
<li>比如用箱形图的办法，超过了上四分位1.5倍四分位距或下四分位1.5倍距离都算异常值，用中位数填充</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; data[&quot;数量&quot;].mean()+data[&quot;数量&quot;].std()*4</span><br><span class="line">b &#x3D; data[&quot;数量&quot;].mean()-data[&quot;数量&quot;].std()*4</span><br><span class="line">c &#x3D; data[&quot;数量&quot;]</span><br><span class="line">c[(c&gt;&#x3D;a)|(c&lt;&#x3D;b)]&#x3D;np.nan</span><br><span class="line">c.fillna(c.median(),inplace&#x3D;True)</span><br><span class="line">print(c.describe())</span><br></pre></td></tr></table></figure>

<ul>
<li>基于绝对离差中位数</li>
</ul>
<p>绝对中位差：如果一个点大于或小于3倍的绝对中位差，那它就被是视为异常点。</p>
<ol>
<li>计算所有观察点的中位数median(x)</li>
<li>计算每个观察点与中位数的绝对偏差值abs(x-median(x))</li>
<li>计算2中的绝对偏差值的中位数，即MAD=median(abs(x-median(x)));</li>
<li>将2得到的值除以3的值，得到一组基于MAD的所有观察点的离中心的距离值abs(x-median(x))/MAD</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from scipy.stats import norm</span><br><span class="line">x&#x3D;np.random.random(100)</span><br><span class="line">number&#x3D;50</span><br><span class="line">x&#x3D;np.r_[x,-60,80,40,100,-100]#在后面添上，相当于padans中merge</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(211)</span><br><span class="line">plt.hist(x,number)</span><br><span class="line">plt.xlabel(&#39;raw&#39;) #没消除异常的时候</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line">def c_except(x,thresh&#x3D;3.5):</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    使用绝对中位差消除异常</span><br><span class="line">    :return:</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    if len(x)&lt;&#x3D;1:</span><br><span class="line">        return</span><br><span class="line">    me&#x3D;np.median(x)</span><br><span class="line">    abs&#x3D;np.absolute(x-me)</span><br><span class="line">    abs_me&#x3D;np.median(abs)</span><br><span class="line"></span><br><span class="line">    score&#x3D;norm.ppf(0.75)*abs&#x2F;abs_me</span><br><span class="line">    return score&lt;thresh</span><br><span class="line"></span><br><span class="line">#异常消除后</span><br><span class="line">x_late&#x3D;x[c_except(x)]</span><br><span class="line">plt.subplot(212)</span><br><span class="line">plt.hist(x_late,number)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>利用平均值或中位数来代替异常点</p>
<h4 id="3-噪声处理-高频去噪"><a href="#3-噪声处理-高频去噪" class="headerlink" title="3.噪声处理(高频去噪)"></a>3.噪声处理(高频去噪)</h4><p>对数据进行分箱操作，然后用每个箱的平均值..来代替箱中的所有数，起到平滑数据的作用。另一种做法是，建立该变量与预测变量的回归模型，根据回归系数和预测变量，反解出自变量的近似值。</p>
<h3 id="二、数据标准化"><a href="#二、数据标准化" class="headerlink" title="二、数据标准化"></a>二、数据标准化</h3><ul>
<li>最大-最小规范化：将数据映射到[0,1]区间</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def minmaxscale(data):</span><br><span class="line">    data&#x3D;(data-data.min())&#x2F;(data.max()-data.min())</span><br><span class="line">    return data</span><br></pre></td></tr></table></figure>
<ul>
<li>z-score标准化</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def standardscale(data):</span><br><span class="line">    data&#x3D;(data-data.mean())&#x2F;data.std()</span><br><span class="line">    return data</span><br></pre></td></tr></table></figure>
<ul>
<li>log变换<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def decimalscale(data):</span><br><span class="line">    data&#x3D;data&#x2F;10**np.log10(data.abs().max()))</span><br><span class="line">    return data</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="三、小波变换和小波阈值法去噪"><a href="#三、小波变换和小波阈值法去噪" class="headerlink" title="三、小波变换和小波阈值法去噪"></a>三、小波变换和小波阈值法去噪</h3><p>小波变换是一种信号的时间-尺度（时间-频率）分析方法，它具有多分辨分析的特点，而且在时域两域都具有表征信号局部特征的能力，是一种窗口大小固定不变但是其形状可变的，时间窗和频率窗都可改变的时域局部化分析方法。即在低频部分具有较低的时间分辨率和较高的频率分辨率，在高频部分具有较高的时间分辨率和较低的频率分辨率，很适合于分析非平稳的信号和提取信号的局部特征，所以小波变换称为分析处理信号的显微镜。</p>
<h4 id="小波阈值去噪："><a href="#小波阈值去噪：" class="headerlink" title="小波阈值去噪："></a>小波阈值去噪：</h4><p>在小波分析中经常使用到近似和细节，近似代表信号的高尺度，即低频信息；细节表示信号的低尺度，即高频信息。对含有噪声的信号，噪声分量的主要能力集中在小波解的细节分量中。</p>
<p>1.小波基的选择<br>采用db小波系</p>
<p>2.分解层数的选择</p>
<p>层数越大，则噪声和信号表现的不同特征越明显，越有利于二者的分离。但另一方面，参数越多，重构的信号失真也越大，在一定程度上又会影响最终去噪的效果。</p>
<p>通常小波分解的频段范围与采样频率有关。若N层分解，则各个频段大小为Fs/2/2^N 。例如：一个原始信号，经历的时间长度为2秒，采样了2000个点，那么做除法，可得出采样频率为1000hz，由采样定理（做除法）得该信号的最大频率为500hz，那么对该信号做3层的DWT，一阶细节的频段为250－500hz，一阶逼近的频段为小于250hz，二阶细节的频段为125－250hz，逼近的频段为小于125hz，三阶细节的频段约为62.5－125hz，逼近的频段为小于62.5hz。对于更多阶的分解也是以此类推的。</p>
<p>3.阈值的选取</p>
<p>目前的常见的阈值选择方法有：固定阈值估计、极值阈值估计、无偏似然估计以及启发式估计。</p>
<p>4.阈值函数的选择</p>
<p>确定了高斯白噪声在小波系数(域)的阈值门限之后，就需要有个阈值函数对这个含有噪声系数的小波系数进行过滤，去除高斯噪声系数，常用的阈值函数有软阈值和硬阈值方法，很多文献论文中也有在阈值函数进行一些大量的改进和优化。</p>
<h5 id="pywavelet基于阈值的小波分解重构法去噪"><a href="#pywavelet基于阈值的小波分解重构法去噪" class="headerlink" title="pywavelet基于阈值的小波分解重构法去噪"></a>pywavelet基于阈值的小波分解重构法去噪</h5><p>小波阈值去噪的具体处理过程，选择一个小波并确定分解层数，然后将含噪信号在各尺度上进行小波分解，保留大尺度低频率下的全部小波系数；对于各尺度高分辨率下的小波系数，可以设定一个阈值，幅度低于该阈值的小波系数设为0，高于该阈值的小波系数完整保留。最后利用逆小波变换重构，恢复出有效的信号。</p>
<p>matlab小波去噪</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">clear all;clc </span><br><span class="line">load(‘Audio_1_resample.mat’); </span><br><span class="line">s&#x3D;data_resample;   %获取要处理的信号，data_resample是在上面.mat里的一个参数 </span><br><span class="line">%整个信号的长度 </span><br><span class="line">N &#x3D; numel(s); </span><br><span class="line">%小波分解; </span><br><span class="line">[c,l]&#x3D;wavedec(s,7,’coif5’);   %小波基为coif5,分解层数为7层  </span><br><span class="line">ca11&#x3D;appcoef(c,l,’coif5’,7);    %获取低频信号 </span><br><span class="line">cd1&#x3D;detcoef(c,l,1); </span><br><span class="line">cd2&#x3D;detcoef(c,l,2);            %获取高频细节 </span><br><span class="line">cd3&#x3D;detcoef(c,l,3); </span><br><span class="line">cd4&#x3D;detcoef(c,l,4); </span><br><span class="line">cd5&#x3D;detcoef(c,l,5); </span><br><span class="line">cd6&#x3D;detcoef(c,l,6); </span><br><span class="line">cd7&#x3D;detcoef(c,l,7); </span><br><span class="line">sd1&#x3D;zeros(1,length(cd1)); </span><br><span class="line">sd2&#x3D;zeros(1,length(cd2));      %1-3层置0,4-7层用软阈值函数处理 </span><br><span class="line">sd3&#x3D;zeros(1,length(cd3)); </span><br><span class="line">sd4&#x3D;wthresh(cd4,’s’,0.014); </span><br><span class="line">sd5&#x3D;wthresh(cd5,’s’,0.014); </span><br><span class="line">sd6&#x3D;wthresh(cd6,’s’,0.014); </span><br><span class="line">sd7&#x3D;wthresh(cd7,’s’,0.014); </span><br><span class="line">c2&#x3D;[ca11,sd7,sd6,sd5,sd4,sd3,sd2,sd1]; </span><br><span class="line">s0&#x3D;waverec(c2,l,’coif5’);                 %小波重构 </span><br><span class="line">figure; </span><br><span class="line">subplot(211);plot(s);subplot(212);plot(s0);%画图</span><br></pre></td></tr></table></figure>

<p><a href="https://wenku.baidu.com/view/84fe78a1284ac850ad02423c.html" target="_blank" rel="noopener">baiduwenku</a></p>
<p><a href="https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction" target="_blank" rel="noopener">数据来源</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import pywt</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">import matplotlib  </span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">####################一些参数和函数############</span><br><span class="line"></span><br><span class="line">def sgn(num):</span><br><span class="line"></span><br><span class="line">    if(num &gt; 0.0):</span><br><span class="line"></span><br><span class="line">        return 1.0</span><br><span class="line"></span><br><span class="line">    elif(num &#x3D;&#x3D; 0.0):</span><br><span class="line"></span><br><span class="line">        return 0.0</span><br><span class="line"></span><br><span class="line">    else:</span><br><span class="line"></span><br><span class="line">        return -1.0</span><br><span class="line"></span><br><span class="line">begin &#x3D; 1</span><br><span class="line"></span><br><span class="line">end &#x3D; 1001</span><br><span class="line"></span><br><span class="line">###软硬阈值折衷法 a 参数</span><br><span class="line"></span><br><span class="line">a &#x3D; 0.5</span><br><span class="line"></span><br><span class="line">###################一些参数和函数############# </span><br><span class="line"></span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">###sample###  </span><br><span class="line"></span><br><span class="line">#x &#x3D; [3, 7, 1, 1, -2, 5, 4, 6]</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">#read data</span><br><span class="line"></span><br><span class="line">data &#x3D; pd.read_csv(&#39;energydata_complete.csv&#39; )</span><br><span class="line"></span><br><span class="line">#y_value为原信号</span><br><span class="line"></span><br><span class="line">##########画图################################################</span><br><span class="line"></span><br><span class="line">x1 &#x3D; range(begin, end)</span><br><span class="line"></span><br><span class="line">y_values &#x3D;  data[&#39;RH_6&#39;][begin:end]</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">scatter() </span><br><span class="line"></span><br><span class="line">x:横坐标 y:纵坐标 s:点的尺寸</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">#plt.scatter(x1, y_values, s&#x3D;10)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">plt.plot(x1, y_values) </span><br><span class="line"></span><br><span class="line">## 设置图表标题并给坐标轴加上标签</span><br><span class="line"></span><br><span class="line">#plt.title(&#39;plot Numbers&#39;, fontsize&#x3D;24)</span><br><span class="line"></span><br><span class="line">#plt.xlabel(&#39;xValue&#39;, fontsize&#x3D;14)</span><br><span class="line"></span><br><span class="line">#plt.ylabel(&#39;yValue&#39;, fontsize&#x3D;14)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># 设置刻度标记的大小</span><br><span class="line"></span><br><span class="line">#plt.tick_params(axis&#x3D;&#39;both&#39;, which&#x3D;&#39;major&#39;, labelsize&#x3D;14)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># 设置每个坐标轴的取值范围</span><br><span class="line"></span><br><span class="line">#plt.axis([0, 1000, 0, 100])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">##############画图############################################</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">#print(data.shape)</span><br><span class="line"></span><br><span class="line">#print(data)</span><br><span class="line"></span><br><span class="line">#print(data[&#39;RH_6&#39;])</span><br><span class="line"></span><br><span class="line">##################去噪#########################</span><br><span class="line"></span><br><span class="line">db1  &#x3D; pywt.Wavelet(&#39;db1&#39;)</span><br><span class="line"></span><br><span class="line">#[ca3, cd3, cd2, cd1] &#x3D; pywt.wavedec(x, db1)</span><br><span class="line"></span><br><span class="line">#print(ca3)</span><br><span class="line"></span><br><span class="line">#print(cd3)</span><br><span class="line"></span><br><span class="line">#print(cd2)</span><br><span class="line"></span><br><span class="line">#print(cd1)</span><br><span class="line"></span><br><span class="line">#分解为三层</span><br><span class="line"></span><br><span class="line">coeffs &#x3D; pywt.wavedec(y_values, db1, level &#x3D; 3)</span><br><span class="line"></span><br><span class="line">print(&quot;------------------len of coeffs---------------------&quot;)</span><br><span class="line"></span><br><span class="line">print(len(coeffs))</span><br><span class="line"></span><br><span class="line">#print(coeffs)</span><br><span class="line"></span><br><span class="line">recoeffs &#x3D; pywt.waverec(coeffs, db1)</span><br><span class="line"></span><br><span class="line">#print(recoeffs)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">thcoeffs &#x3D;[]</span><br><span class="line"></span><br><span class="line">for i in range(1, len(coeffs)):</span><br><span class="line"></span><br><span class="line">    tmp &#x3D; coeffs[i].copy()</span><br><span class="line"></span><br><span class="line">    Sum &#x3D; 0.0</span><br><span class="line"></span><br><span class="line">    for j in coeffs[i]:</span><br><span class="line"></span><br><span class="line">        Sum &#x3D; Sum + abs(j)</span><br><span class="line"></span><br><span class="line">    N &#x3D; len(coeffs[i])</span><br><span class="line"></span><br><span class="line">    Sum &#x3D; (1.0 &#x2F; float(N)) * Sum</span><br><span class="line"></span><br><span class="line">    sigma &#x3D; (1.0 &#x2F; 0.6745) * Sum</span><br><span class="line"></span><br><span class="line">    lamda &#x3D; sigma * math.sqrt(2.0 * math.log(float(N), math.e))</span><br><span class="line"></span><br><span class="line">    for k in range(len(tmp)):</span><br><span class="line"></span><br><span class="line">        if(abs(tmp[k]) &gt;&#x3D; lamda):</span><br><span class="line"></span><br><span class="line">            tmp[k] &#x3D; sgn(tmp[k]) * (abs(tmp[k]) - a * lamda)</span><br><span class="line"></span><br><span class="line">        else:</span><br><span class="line"></span><br><span class="line">            tmp[k] &#x3D; 0.0</span><br><span class="line"></span><br><span class="line">    thcoeffs.append(tmp)</span><br><span class="line"></span><br><span class="line">#print(thcoeffs)</span><br><span class="line"></span><br><span class="line">usecoeffs &#x3D; []</span><br><span class="line"></span><br><span class="line">usecoeffs.append(coeffs[0])</span><br><span class="line"></span><br><span class="line">usecoeffs.extend(thcoeffs)</span><br><span class="line"></span><br><span class="line">#print(usecoeffs)</span><br><span class="line"></span><br><span class="line">#recoeffs为去噪后信号</span><br><span class="line"></span><br><span class="line">recoeffs &#x3D; pywt.waverec(usecoeffs, db1)</span><br><span class="line"></span><br><span class="line">#print(recoeffs)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">##########画图################################################</span><br><span class="line"></span><br><span class="line">x1 &#x3D; range(begin, end)</span><br><span class="line"></span><br><span class="line">y_values &#x3D;  recoeffs</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">scatter() </span><br><span class="line"></span><br><span class="line">x:横坐标 y:纵坐标 s:点的尺寸</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">#plt.scatter(x1, y_values, s&#x3D;10)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">plt.plot(x1, y_values) </span><br><span class="line"></span><br><span class="line">## 设置图表标题并给坐标轴加上标签</span><br><span class="line"></span><br><span class="line">#plt.title(&#39;plot Numbers&#39;, fontsize&#x3D;24)</span><br><span class="line"></span><br><span class="line">#plt.xlabel(&#39;xValue&#39;, fontsize&#x3D;14)</span><br><span class="line"></span><br><span class="line">#plt.ylabel(&#39;yValue&#39;, fontsize&#x3D;14)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># 设置刻度标记的大小</span><br><span class="line"></span><br><span class="line">#plt.tick_params(axis&#x3D;&#39;both&#39;, which&#x3D;&#39;major&#39;, labelsize&#x3D;14)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># 设置每个坐标轴的取值范围</span><br><span class="line"></span><br><span class="line">#plt.axis([0, 1000, 0, 100])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">##############画图############################################</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/carryheart/article/details/79610805" target="_blank" rel="noopener">link</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/26/%E5%9F%BA%E4%BA%8Ekeras%E7%9A%84LSTM%E5%A4%9A%E5%8F%98%E9%87%8F%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/26/%E5%9F%BA%E4%BA%8Ekeras%E7%9A%84LSTM%E5%A4%9A%E5%8F%98%E9%87%8F%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/" class="post-title-link" itemprop="url">基于keras的LSTM多变量时间序列预测</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-26 15:29:28 / 修改时间：15:30:01" itemprop="dateCreated datePublished" datetime="2020-01-26T15:29:28+08:00">2020-01-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>利用深度学习库keras搭建LSTM模型来处理多个变量的时间序列预测问题</p>
<h5 id="1-如何将原始数据转化为适合处理时序预测问题的数据格式"><a href="#1-如何将原始数据转化为适合处理时序预测问题的数据格式" class="headerlink" title="1.如何将原始数据转化为适合处理时序预测问题的数据格式"></a>1.如何将原始数据转化为适合处理时序预测问题的数据格式</h5><h5 id="2-如何准备数据并搭建LSTM来处理时序预测问题"><a href="#2-如何准备数据并搭建LSTM来处理时序预测问题" class="headerlink" title="2.如何准备数据并搭建LSTM来处理时序预测问题"></a>2.如何准备数据并搭建LSTM来处理时序预测问题</h5><h5 id="3-如何利用模型预测"><a href="#3-如何利用模型预测" class="headerlink" title="3.如何利用模型预测"></a>3.如何利用模型预测</h5><h3 id="1-空气污染预测"><a href="#1-空气污染预测" class="headerlink" title="1.空气污染预测"></a>1.空气污染预测</h3><p>数据集包括行数、日期（年；月；日；小时）、PM2.5浓度、露点、温度、大气压、风向、风速、累计小时雪景、累计小时鱼量</p>
<h3 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h3><p>粗略的观察数据集，需要删除最开始的24小时的PM2.5,对于其他时刻少量的缺省值利用pandas中的fillna填充；同时需要整合日期数据，使其作为pandas中的索引。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from pandas import read_csv</span><br><span class="line">from datetime import datetime</span><br><span class="line"># load data</span><br><span class="line">def parse(x):</span><br><span class="line">    return datetime.strptime(x, &#39;%Y %m %d %H&#39;)</span><br><span class="line">dataset &#x3D; read_csv(&#39;raw.csv&#39;,  parse_dates &#x3D; [[&#39;year&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]], index_col&#x3D;0, date_parser&#x3D;parse)</span><br><span class="line">dataset.drop(&#39;No&#39;, axis&#x3D;1, inplace&#x3D;True)</span><br><span class="line"># manually specify column names</span><br><span class="line">dataset.columns &#x3D; [&#39;pollution&#39;, &#39;dew&#39;, &#39;temp&#39;, &#39;press&#39;, &#39;wnd_dir&#39;, &#39;wnd_spd&#39;, &#39;snow&#39;, &#39;rain&#39;]</span><br><span class="line">dataset.index.name &#x3D; &#39;date&#39;</span><br><span class="line"># mark all NA values with 0</span><br><span class="line">dataset[&#39;pollution&#39;].fillna(0, inplace&#x3D;True)</span><br><span class="line"># drop the first 24 hours</span><br><span class="line">dataset &#x3D; dataset[24:]</span><br><span class="line"># summarize first 5 rows</span><br><span class="line">print(dataset.head(5))</span><br><span class="line"># save to file</span><br><span class="line">dataset.to_csv(&#39;pollution.csv&#39;)</span><br></pre></td></tr></table></figure>
<p>将参数绘制图像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from pandas import read_csv</span><br><span class="line">from matplotlib import pyplot</span><br><span class="line"># load dataset</span><br><span class="line">dataset &#x3D; read_csv(&#39;pollution.csv&#39;, header&#x3D;0, index_col&#x3D;0)</span><br><span class="line">values &#x3D; dataset.values</span><br><span class="line"># specify columns to plot</span><br><span class="line">groups &#x3D; [0, 1, 2, 3, 5, 6, 7]</span><br><span class="line">i &#x3D; 1</span><br><span class="line"># plot each column</span><br><span class="line">pyplot.figure()</span><br><span class="line">for group in groups:</span><br><span class="line">    pyplot.subplot(len(groups), 1, i)</span><br><span class="line">    pyplot.plot(values[:, group])</span><br><span class="line">    pyplot.title(dataset.columns[group], y&#x3D;0.5, loc&#x3D;&#39;right&#39;)</span><br><span class="line">    i +&#x3D; 1</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<h3 id="3-多变量LSTM预测模型"><a href="#3-多变量LSTM预测模型" class="headerlink" title="3.多变量LSTM预测模型"></a>3.多变量LSTM预测模型</h3><p>　下面代码中首先加载“pollution.csv”文件，并利用sklearn的预处理模块对类别特征“风向”进行编码，当然也可以对该特征进行one-hot编码。<br>　　接着对所有的特征进行归一化处理，然后将数据集转化为有监督学习问题，同时将需要预测的当前时刻（t）的天气条件特征移除，完整代码如下：
　　</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># convert series to supervised learning</span><br><span class="line">def series_to_supervised(data, n_in&#x3D;1, n_out&#x3D;1, dropnan&#x3D;True):</span><br><span class="line">    n_vars &#x3D; 1 if type(data) is list else data.shape[1]</span><br><span class="line">    df &#x3D; DataFrame(data)</span><br><span class="line">    cols, names &#x3D; list(), list()</span><br><span class="line">    # input sequence (t-n, ... t-1)</span><br><span class="line">    for i in range(n_in, 0, -1):</span><br><span class="line">        cols.append(df.shift(i))</span><br><span class="line">        names +&#x3D; [(&#39;var%d(t-%d)&#39; % (j+1, i)) for j in range(n_vars)]</span><br><span class="line">    # forecast sequence (t, t+1, ... t+n)</span><br><span class="line">    for i in range(0, n_out):</span><br><span class="line">        cols.append(df.shift(-i))</span><br><span class="line">        if i &#x3D;&#x3D; 0:</span><br><span class="line">            names +&#x3D; [(&#39;var%d(t)&#39; % (j+1)) for j in range(n_vars)]</span><br><span class="line">        else:</span><br><span class="line">            names +&#x3D; [(&#39;var%d(t+%d)&#39; % (j+1, i)) for j in range(n_vars)]</span><br><span class="line">    # put it all together</span><br><span class="line">    agg &#x3D; concat(cols, axis&#x3D;1)</span><br><span class="line">    agg.columns &#x3D; names</span><br><span class="line">    # drop rows with NaN values</span><br><span class="line">    if dropnan:</span><br><span class="line">        agg.dropna(inplace&#x3D;True)</span><br><span class="line">    return agg</span><br><span class="line"></span><br><span class="line"># load dataset</span><br><span class="line">dataset &#x3D; read_csv(&#39;pollution.csv&#39;, header&#x3D;0, index_col&#x3D;0)</span><br><span class="line">values &#x3D; dataset.values</span><br><span class="line"># integer encode direction</span><br><span class="line">encoder &#x3D; LabelEncoder()</span><br><span class="line">values[:,4] &#x3D; encoder.fit_transform(values[:,4])</span><br><span class="line"># ensure all data is float</span><br><span class="line">values &#x3D; values.astype(&#39;float32&#39;)</span><br><span class="line"># normalize features</span><br><span class="line">scaler &#x3D; MinMaxScaler(feature_range&#x3D;(0, 1))</span><br><span class="line">scaled &#x3D; scaler.fit_transform(values)</span><br><span class="line"># frame as supervised learning</span><br><span class="line">reframed &#x3D; series_to_supervised(scaled, 1, 1)</span><br><span class="line"># drop columns we don&#39;t want to predict</span><br><span class="line">reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis&#x3D;1, inplace&#x3D;True)</span><br><span class="line">print(reframed.head())</span><br></pre></td></tr></table></figure>
<p>构造模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># split into train and test sets</span><br><span class="line">values &#x3D; reframed.values</span><br><span class="line">n_train_hours &#x3D; 365 * 24</span><br><span class="line">train &#x3D; values[:n_train_hours, :]</span><br><span class="line">test &#x3D; values[n_train_hours:, :]</span><br><span class="line"># split into input and outputs</span><br><span class="line">train_X, train_y &#x3D; train[:, :-1], train[:, -1]</span><br><span class="line">test_X, test_y &#x3D; test[:, :-1], test[:, -1]</span><br><span class="line"># reshape input to be 3D [samples, timesteps, features]</span><br><span class="line">train_X &#x3D; train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))</span><br><span class="line">test_X &#x3D; test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))</span><br><span class="line">print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)</span><br></pre></td></tr></table></figure>
<p>现在可以搭建LSTM模型了。 </p>
<p>　　LSTM模型中，隐藏层有50个神经元，输出层1个神经元（回归问题），输入变量是一个时间步（t-1）的特征，损失函数采用Mean Absolute Error(MAE)，优化算法采用Adam，模型采用50个epochs并且每个batch的大小为72。<br>　　<br>　　最后，在fit()函数中设置validation_data参数，记录训练集和测试集的损失，并在完成训练和测试后绘制损失图。
　　</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># design network</span><br><span class="line">model &#x3D; Sequential()</span><br><span class="line">model.add(LSTM(50, input_shape&#x3D;(train_X.shape[1], train_X.shape[2])))</span><br><span class="line">model.add(Dense(1))</span><br><span class="line">model.compile(loss&#x3D;&#39;mae&#39;, optimizer&#x3D;&#39;adam&#39;)</span><br><span class="line"># fit network</span><br><span class="line">history &#x3D; model.fit(train_X, train_y, epochs&#x3D;50, batch_size&#x3D;72, validation_data&#x3D;(test_X, test_y), verbose&#x3D;2, shuffle&#x3D;False)</span><br><span class="line"># plot history</span><br><span class="line">pyplot.plot(history.history[&#39;loss&#39;], label&#x3D;&#39;train&#39;)</span><br><span class="line">pyplot.plot(history.history[&#39;val_loss&#39;], label&#x3D;&#39;test&#39;)</span><br><span class="line">pyplot.legend()</span><br><span class="line">pyplot.show()</span><br><span class="line"></span><br><span class="line"># design network</span><br><span class="line">model &#x3D; Sequential()</span><br><span class="line">model.add(LSTM(50, input_shape&#x3D;(train_X.shape[1], train_X.shape[2])))</span><br><span class="line">model.add(Dense(1))</span><br><span class="line">model.compile(loss&#x3D;&#39;mae&#39;, optimizer&#x3D;&#39;adam&#39;)</span><br><span class="line"># fit network</span><br><span class="line">history &#x3D; model.fit(train_X, train_y, epochs&#x3D;50, batch_size&#x3D;72, validation_data&#x3D;(test_X, test_y), verbose&#x3D;2, shuffle&#x3D;False)</span><br><span class="line"># plot history</span><br><span class="line">pyplot.plot(history.history[&#39;loss&#39;], label&#x3D;&#39;train&#39;)</span><br><span class="line">pyplot.plot(history.history[&#39;val_loss&#39;], label&#x3D;&#39;test&#39;)</span><br><span class="line">pyplot.legend()</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>模型评估</p>
<p>　接下里我们对模型效果进行评估。<br>　<br>　　值得注意的是：需要将预测结果和部分测试集数据组合然后进行比例反转，同时也需要将测试集上的预期值也进行比例转换。 </p>
<p>　　至于在这里为什么进行比例反转，是因为我们将原始数据进行了预处理（连同输出值y），此时的误差损失计算是在处理之后的数据上进行的，为了计算在原始比例上的误差需要将数据进行转化。同时笔者有个小Tips：就是反转时的矩阵大小一定要和原来的大小（shape）完全相同，否则就会报错。<br>　　<br>　通过以上处理之后，再结合RMSE（均方根误差）计算损失。
　</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># make a prediction</span><br><span class="line">yhat &#x3D; model.predict(test_X)</span><br><span class="line">test_X &#x3D; test_X.reshape((test_X.shape[0], test_X.shape[2]))</span><br><span class="line"># invert scaling for forecast</span><br><span class="line">inv_yhat &#x3D; concatenate((yhat, test_X[:, 1:]), axis&#x3D;1)</span><br><span class="line">inv_yhat &#x3D; scaler.inverse_transform(inv_yhat)</span><br><span class="line">inv_yhat &#x3D; inv_yhat[:,0]</span><br><span class="line"># invert scaling for actual</span><br><span class="line">test_y &#x3D; test_y.reshape((len(test_y), 1))</span><br><span class="line">inv_y &#x3D; concatenate((test_y, test_X[:, 1:]), axis&#x3D;1)</span><br><span class="line">inv_y &#x3D; scaler.inverse_transform(inv_y)</span><br><span class="line">inv_y &#x3D; inv_y[:,0]</span><br><span class="line"># calculate RMSE</span><br><span class="line">rmse &#x3D; sqrt(mean_squared_error(inv_y, inv_yhat))</span><br><span class="line">print(&#39;Test RMSE: %.3f&#39; % rmse)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%8B%E8%AF%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%8B%E8%AF%95/" class="post-title-link" itemprop="url">大数据测试</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-26 13:53:34 / 修改时间：13:53:55" itemprop="dateCreated datePublished" datetime="2020-01-26T13:53:34+08:00">2020-01-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一、绪论："><a href="#一、绪论：" class="headerlink" title="一、绪论："></a>一、绪论：</h2><p> 大数据是大容量、高速率、多形态的信息资产，且需要成本效益、信息处理来增加洞察力和决策创新形式。大数据是指大小超出了典型数据库软件工具收集、存储、管理和分析能力的数据集。</p>
<p>大数据分析框架测试、算法质量测试、性能测试、大数据安全和隐私软件测试的经典定义：为发现软件错误，而运行软件的活动。</p>
<p>基本思路：根据软件需求规格说明书，执行软件操作和输入数据，依据软件实际输出结果和预期输出结果来评判软件是否满足规格的要求</p>
<p>本书以Hadoop为主线:底层支撑框架层聚焦于单元测试和框架基准测试；基本算法中涵盖了聚类、分类及其个性化推荐；应用层中，介绍了其性能测试中的若干问题，阐述了数据集的设计与分析；最后讨论了大数据的安全和隐私问题。</p>
<h4 id="大数据特征"><a href="#大数据特征" class="headerlink" title="大数据特征"></a>大数据特征</h4><p>数据类型繁多；处理速度快；数据体量大；数据价值；真实性</p>
<h4 id="大数据的过程模型"><a href="#大数据的过程模型" class="headerlink" title="大数据的过程模型"></a>大数据的过程模型</h4><p>数据源；数据收集及录入；数据过滤及分类；数据分类/建模/预测；数据交付及可视化；消费者的数据分析及应用</p>
<h4 id="大数据相关标准"><a href="#大数据相关标准" class="headerlink" title="大数据相关标准"></a>大数据相关标准</h4><p>大数据相关的标准可分为两大类：基础类和技术类。基础类包括大数据平台技术参考架构、大数据总体技术要求、大数据标准化指南。技术类可分为数据采集、数据存储、数据处理和分析、数据管理。</p>
<p>1.数据采集    数据抽取和预处理等相关规范</p>
<p>2.数据存储     各种类型数据的存储和访问接口规范。</p>
<p>3.数据处理和分析    </p>
<p> 4.数据管理   针对数据的源数据管理、质量管理及数据管理接口规范</p>
<h4 id="大数据的应用"><a href="#大数据的应用" class="headerlink" title="大数据的应用"></a>大数据的应用</h4><p> 趋势预测；疫情分析；消费行为分析；智慧金融；智慧金融；精确营销; 舆情分析;</p>
<h4 id="大数据引起的软件变化"><a href="#大数据引起的软件变化" class="headerlink" title="大数据引起的软件变化"></a>大数据引起的软件变化</h4><p>传统的软件架构无法满足大数据处理的要求；大数据软件处理的结果是未知的；大数据的软件思维模式发生逆转。</p>
<h4 id="软件测试的新挑战"><a href="#软件测试的新挑战" class="headerlink" title="软件测试的新挑战"></a>软件测试的新挑战</h4><p>测试ORACLE问题： 软件测试的基本前提是在确定的输入下，存在确定的输出。测试要将软件运行的实际结果和预期的结果相比较，从而得出软件运行正确与否。</p>
<p>测试能力问题：测试结果的判定问题：在大数据的分析背景下，典型的应用场景不存在确定的输出，大数据的分析的准确性很大程度上依赖于数据的输入和数据的分布特性。</p>
<p>隐私问题：（略）</p>
<h2 id="面向大数据框架的测评"><a href="#面向大数据框架的测评" class="headerlink" title="面向大数据框架的测评"></a>面向大数据框架的测评</h2><p>本章将介绍Hadoop大数据框架的单元测试、大数据的数据清洗、数据质量评估框架以及大数据的基准性能测试技术。</p>
<h4 id="2-1大数据的数据处理流程"><a href="#2-1大数据的数据处理流程" class="headerlink" title="2.1大数据的数据处理流程"></a>2.1大数据的数据处理流程</h4><p>在处理大数据之前需要对来自不同数据源的数据进行数据处理，包括数据抽取和数据集成。通过数据抽取和数据集成操作提取出关系和实体，对其进行关联和聚类的相关操作后，采用统一定义的结构来存储这些数据。数据清洗在数据集成与数据抽取之前，保证数据质量与可行性。</p>
<h4 id="2-2面向数据质量的测评"><a href="#2-2面向数据质量的测评" class="headerlink" title="2.2面向数据质量的测评"></a>2.2面向数据质量的测评</h4><h5 id="数据质量的定义"><a href="#数据质量的定义" class="headerlink" title="数据质量的定义"></a>数据质量的定义</h5><p>数据本身质量：数据真实性、数据完备性、数据自治性。</p>
<p>数据过程质量：数据使用质量、数据存储质量、数据传输质量。</p>
<h5 id="数据质量问题的分类"><a href="#数据质量问题的分类" class="headerlink" title="数据质量问题的分类"></a>数据质量问题的分类</h5><p>略</p>
<h5 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h5><p>1.数据清理</p>
<p>不符合要求的数据：数据缺失；数据错误；数据重复（mapreduce去重）</p>
<p>2.数据集成/数据变换</p>
<p>数据集成是指从逻辑上或者物理上将来源或格式以及特点性质不同的数据有机地集中起来，为数据挖掘提供完整的数据源。</p>
<p>数据集成问题分类：数据表链接不匹配；冗余；数据值冲突。</p>
<p>数据变换：属性的数据类型转换；属性构造；数据离散化；数据标准化。</p>
<p>3.数据规约</p>
<p>可以获得数据集的简化表示；属性选择、实例选择。</p>
<h5 id="数据质量测评"><a href="#数据质量测评" class="headerlink" title="数据质量测评"></a>数据质量测评</h5><p>1.数据清洗框架和工具</p>
<p>数据清洗：映射、匹配、聚集、合并、跟踪。</p>
<p>2.数据清洗评估</p>
<p>相关性；准确性；及时性；完整性；一致性；</p>
<h4 id="2-3分布式数据模型及测试"><a href="#2-3分布式数据模型及测试" class="headerlink" title="2.3分布式数据模型及测试"></a>2.3分布式数据模型及测试</h4><h5 id="框架："><a href="#框架：" class="headerlink" title="框架："></a>框架：</h5><p>Hadoop的核心是HDFS和MapReduce，为用户提供了系统底层透明的分布式基础框架。</p>
<p>mapreduce:分布式数据处理模型和执行环境，运用于大规模的通用计算机集群。</p>
<p>HDFS：Hadoop的分布式文件系统，运用于大规模的通用计算机集群。</p>
<p>HBase:分布式按列存储的数据，使用HDFS作为底层存储，同时支持MapReduce的批量式计算和点查询。</p>
<p>Hive:分布式、按列存储的数据仓库。</p>
<h5 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h5><p>最底层的两个抽象实体，分别是HDFS和MapReduce。</p>
<h5 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h5><p>MRUnit是针对MapReduce的单元测试框架；针对不同的测试对象，MRUnit使用以下几种Driver:</p>
<p>MapDriver   测试单独的Map</p>
<p>ReduceDriver  测试单独的Reduce</p>
<p>MapReduce Driver 将Map与Reduce结合起来测试</p>
<p>从Apache下载MRUnit最新版的jar包，并将jar包添加到hadoop的IDE Classpath 路径中。</p>
<h5 id="测试代码："><a href="#测试代码：" class="headerlink" title="测试代码："></a>测试代码：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public class SMSCDRMapperReducerTest&#123;</span><br><span class="line">    MapDriver&lt;LongWritable,Text,Text,IntWritable&gt;mapDriver; </span><br><span class="line">    ReduceDriver&lt;Text,IntWritable,Text,IntWritable&gt;reduceDriver;</span><br><span class="line">    MapReduceDriver&lt;LongWritable,Text,Text,IntWritable,Text,IntWritable&gt;mapReduceDriver;</span><br><span class="line">    @Before</span><br><span class="line">       public void setUp()&#123;</span><br><span class="line">           SMSCDRMapper mapper &#x3D; new SMSCDRMapper();</span><br><span class="line">           SMSCDReducer reducer &#x3D; new SMSCDRReducer();</span><br><span class="line">           mapReduceDriver &#x3D; MapReduceDriver.newMapReduceDriver(mapper,reducer);</span><br><span class="line">       &#125;</span><br><span class="line">   @Text    </span><br><span class="line">       public void testMapReduce()&#123;</span><br><span class="line">               Text mapInputValue1 &#x3D; new Text(&quot;595877;1;7585458855;4441417;5&quot;)</span><br><span class="line">               Text mapInputValue2 &#x3D; new Text(&quot;735856;1;5498749558;8478941;3&quot;)</span><br><span class="line">               mapReduceDriver.withInput(new LongWritable(1),mapInputValue1);</span><br><span class="line">               mapReduceDriver.withInput(new LongWritable(1),mapInputValue2);</span><br><span class="line">               mapReduceDriver.addOutput(new Text(&quot;5&quot;),new IntWritable(1));</span><br><span class="line">               mapReduceDriver.addOutput(new Text(&quot;3&quot;),new IntWritable(1));</span><br><span class="line">               maReduceDriver.runTest();</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-4大数据的基准测试"><a href="#2-4大数据的基准测试" class="headerlink" title="2.4大数据的基准测试"></a>2.4大数据的基准测试</h4><p>基准测试是一种测量和评估软件性能指标的典型活动。可以在某个时刻通过基准测试建立一个已知的性能水平，当系统的软硬件环境发生变化后再进行一次基准测试，以确定那些变化对性能的影响。</p>
<h5 id="2-4-1测试方法"><a href="#2-4-1测试方法" class="headerlink" title="2.4.1测试方法"></a>2.4.1测试方法</h5><h6 id="1）测试步骤"><a href="#1）测试步骤" class="headerlink" title="1）测试步骤"></a>1）测试步骤</h6><p>通常是在系统上运行一系列的测试程序，并把性能计数器的结果保存起来，这些结果称为“性能指标”。</p>
<h6 id="2）测试工具集"><a href="#2）测试工具集" class="headerlink" title="2）测试工具集"></a>2）测试工具集</h6><p>包括工业界、科研界提出的测试工具集和大数据提供的测试基准。</p>
<p>具体包括：</p>
<p>1.BigBench</p>
<p>2.hadoop自带的测试基准，这些程序可以从多个角度对Hadoop进行测试，TestDFSIO,mrbench和nnbench是三个广泛使用的测试。</p>
<p>TestDFSIO用于测试HDFS的IO性能。</p>
<p>nnbench用于测试NameNode负载。</p>
<p>mrbench会多次重复执行一个小作业，用于检查在机群上小作业的运行是否可以重复以及运行是否高效。</p>
<p>3.HBase系统本身提供了性能测试工具。</p>
<h6 id="3）数据准备"><a href="#3）数据准备" class="headerlink" title="3）数据准备"></a>3）数据准备</h6><p>数据基准测试中常用的数据生成工具包括HiBench与BDGS。</p>
<p>HiBench的容量是扩展的，可以生成非结构的文本数据类型并支持hadoop hive。BDGS在保留原始数据特性的基础上以小规模的真实数据生成大规模的数据。</p>
<p>并行数据生成框架是一种适应性很强的数据生成工具，可以在短时间内生成大量的关系数据。PDGF利用并行随机数发生器来生成独立的相关值。</p>
<h5 id="2-4-2测试内容"><a href="#2-4-2测试内容" class="headerlink" title="2.4.2测试内容"></a>2.4.2测试内容</h5><p>下面给出不同的测试工具集包括的测试内容：</p>
<p>1.big data bench from uc berkeley<br>redshift \hive\shark\impala</p>
<p>2.bigdatabench</p>
<p>3.hibench基准测试</p>
<p>4.hadoop基准测试</p>
<p>TestDFSIO的测试步骤：</p>
<p>用法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Usage: TestDFSIO[genericOptions]   -read|-write|-append|-clean[-nrFiles N]</span><br></pre></td></tr></table></figure>
<p>命令行：</p>
<p>例子将往HDFS中写入10个1000MB的文件： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop - *test*.jar TestDFSIO -read -nrFiles 10  -fileSize 1000</span><br></pre></td></tr></table></figure>
<p>nnbench：用于测试NameNode的负载，它会生成很多与HDFRS相关的请求，给NameNode施加压力。<br>例如，使用12个mapper和6个reducer来创建1000个文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop - *test*.jar nnbench\</span><br><span class="line">   -operation create_write -maps 12 -reduces 6 -blockSize 1\</span><br><span class="line">   -bytesToWrite 0 -numberOfFiles 1000 -replicationFactorPerFiles 3\</span><br><span class="line">   -readFileAfterOpen true -baseDir&#x2F;benchmarks&#x2F;NNBench - &#39;hostname -s&#39;</span><br></pre></td></tr></table></figure>
<p>mrbench会多次重复执行一个小作业，用于检查在机群上小作业的运行是否可以重复以及运行是否高效。<br>例如，运行一个小作业50次。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop - *test*.jar mrbench -numRuns 50</span><br></pre></td></tr></table></figure>
<p>Terasort是测试Hadoop的一个有效的排序程序。通过Hadoop自带的Terasort排序程序，测试不同的Map任务和Reduce 任务数量，对hadoop性能的影响。<br>一个完整的Terasort测试需要按三个步骤执行：</p>
<p>1.用TeraGen生成1GB的随机数据，并输入到目录/examples/terasort- input</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop-examples-0.20.2-cdh3u3.jar teragen \</span><br><span class="line">    10000000&#x2F;examples&#x2F;terasort- input</span><br></pre></td></tr></table></figure>
<p>2.输入数据运行TeraSort对数据进行排序，并将结果输出到目录：examples/terasort- output</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop-examples-0.20.2-cdh3u3.jar terasort \</span><br><span class="line">    examples&#x2F;terasort- input&#x2F;examples&#x2F;terasort- output</span><br></pre></td></tr></table></figure>
<p>3.用TeraValidate验证排好序的输出数据，如果有问题，将乱序的Key输出到目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop-examples-0.20.2-cdh3u3.jar teravalidate \                            </span><br><span class="line">      examples&#x2F;terasort- input&#x2F;examples&#x2F;terasort- validate</span><br></pre></td></tr></table></figure>
<p>5.微基准测试</p>
<p>用hadoop对sort greo,wordcount进行微基准测试实例，包括数据生成和测试执行两步骤。</p>
<p>6.关系查询</p>
<p>针对数据库中的相关信息进行，基准测试主要包括：装载数据、查询准备和执行查询三个步骤。</p>
<p>7.HBase</p>
<p>HBase自带的测试主要步骤</p>
<p>1）环境配置<br>2）测试<br>3）Bulk load对HBase测试</p>
<h2 id="三-大数据智能算法及测评技术"><a href="#三-大数据智能算法及测评技术" class="headerlink" title="三.大数据智能算法及测评技术"></a>三.大数据智能算法及测评技术</h2><h4 id="3-1概述"><a href="#3-1概述" class="headerlink" title="3.1概述"></a>3.1概述</h4><p>大数据基础算法：</p>
<p>聚类算法与评估：层次聚类、流聚类、K-均值。</p>
<p>分类算法与评估：朴素贝叶斯、支持向量机、K近邻</p>
<p>大数据应用算法：</p>
<p>推荐系统算法与评估：用户聚类、物品聚类、用户行为分类、推荐算法</p>
<h4 id="3-2聚类算法及测评"><a href="#3-2聚类算法及测评" class="headerlink" title="3.2聚类算法及测评"></a>3.2聚类算法及测评</h4><p>聚类的目的是在海量或难以理解的数据集中发现层次和规律，或让数据集更容易被理解，属于无监督机器学习算法。</p>
<h5 id="聚类的典型算法及分析"><a href="#聚类的典型算法及分析" class="headerlink" title="聚类的典型算法及分析"></a>聚类的典型算法及分析</h5><p>1.层次聚类法</p>
<p>1）首先开始将每个点视为簇</p>
<p>2）找出所有簇中距离最近的两个簇</p>
<p>3）合并成为一个新的簇</p>
<p>4）重复步骤</p>
<p>算法思想非常简单，仅可适用于规模相对较小的数据集。</p>
<p>2.K-均值聚类算法</p>
<p>1）首先选择K个点，称为聚类质心</p>
<p>2）遍历数据集中的每个点，按照距离K个质心的距离，将其与距离最近的质心关联起来，与同一质心相关联的所有点聚成一类。</p>
<p>3）计算每一类中所有点位置的均值，将该类的质心移动到新质心的位置。</p>
<p>4）重复上述步骤。</p>
<p>3.并行化聚类法<br>将聚类算法部署在MapReduce框架中能够大大提高算法的并行程度。</p>
<p>K-均值算法目前已经在Apache的开源机器学习软件库中已经实现。</p>
<h5 id="聚类算法的测试与评估"><a href="#聚类算法的测试与评估" class="headerlink" title="聚类算法的测试与评估"></a>聚类算法的测试与评估</h5><p>略</p>
<h4 id="3-3分类算法及评估"><a href="#3-3分类算法及评估" class="headerlink" title="3.3分类算法及评估"></a>3.3分类算法及评估</h4><p>有监督的机器学习</p>
<p>朴素贝叶斯分类算法</p>
<p>支持向量机算法 ：数据集总体上是线性可分的。对于线性不可分的情况，支持向量机的核心思想是将输入数据的特征向量映射到高维的特征向量空间，并在该特征空间中构造最优的分类面，这种方法称为核技巧。</p>
<p>并行化分类算法</p>
<p>分类算法的测试（略）</p>
<p>分类器性能的评估（略）</p>
<h4 id="3-4推荐系统算法及其测评"><a href="#3-4推荐系统算法及其测评" class="headerlink" title="3.4推荐系统算法及其测评"></a>3.4推荐系统算法及其测评</h4><p>一个完整的推荐系统主要由四个核心模块组成：用户特征的收集模块、用户行为的建模与分析模块、物品的排序与推荐模块、推荐系统的评估模块。</p>
<p>1）基于内容的推荐算法</p>
<p>根据物品的特征来计算物品与物品之间的相似度  。</p>
<p>2）基于用户的协同过滤推荐</p>
<p>一个用户会喜欢和他有相似偏好的用户喜欢的物品。计算用户的相似度，找到与目标用户偏好相似的用户集合。在这个用户集合中分析并找出目标用户可能喜欢，并且没有听说过的物品推荐给用户。</p>
<p>3）基于物品的协同过滤推荐</p>
<p>一个用户会喜欢和他之前喜欢的物品类似的物品。<br>计算物品之间的相似度。根据物品之间的相似度和用户的历史行为给用户推荐他们可能感兴趣的物品。</p>
<p>推荐系统的测评实现（略）</p>
<p>推荐系统评估（略）</p>
<h2 id="四-大数据应用的性能测试技术"><a href="#四-大数据应用的性能测试技术" class="headerlink" title="四.大数据应用的性能测试技术"></a>四.大数据应用的性能测试技术</h2><p>性能测试包括并发测试、负载测试、压力测试和容量测试。</p>
<p>1.应用性能指标：</p>
<p>呈现时间、数据传输时间、系统处理时间。<br>性能度量数据包括：<br>响应时间、用户数、吞吐量。</p>
<p>2.监控指标：</p>
<p> 用户监控、在某段时间内在线人数监控、页面访问次数等等。<br> 大数据的数据结构特点：</p>
<h4 id="4-1大数据应用的性能测评模型"><a href="#4-1大数据应用的性能测评模型" class="headerlink" title="4.1大数据应用的性能测评模型"></a>4.1大数据应用的性能测评模型</h4><h5 id="4-1-1应用负载模型"><a href="#4-1-1应用负载模型" class="headerlink" title="4.1.1应用负载模型"></a>4.1.1应用负载模型</h5><p>略</p>
<h5 id="4-1-2数据负载模型"><a href="#4-1-2数据负载模型" class="headerlink" title="4.1.2数据负载模型"></a>4.1.2数据负载模型</h5><p>性能测试流程：<br>需求分析、测试方案、测试设计、测试开发、环境准备、测试执行、结果汇总、分析调优。结构化数据、非结构化数据、半结构化数据。</p>
<h2 id="五-大数据应用的安全测评技术"><a href="#五-大数据应用的安全测评技术" class="headerlink" title="五.大数据应用的安全测评技术"></a>五.大数据应用的安全测评技术</h2><h4 id="5-1影响架构安全的因素"><a href="#5-1影响架构安全的因素" class="headerlink" title="5.1影响架构安全的因素"></a>5.1影响架构安全的因素</h4><h5 id="1）分布式计算框架安全"><a href="#1）分布式计算框架安全" class="headerlink" title="1）分布式计算框架安全"></a>1）分布式计算框架安全</h5><p>MapReduce是常用的分布式计算框架，由map和reduce两个函数组成。map函数主要负责读入输入数据，把它分成可以用相同方法解决的小数据块，然后把这些小数据块分发到不同的节点上，每一个工作节点做同样的事，再把处理的结果返回reduce函数。reduce函数把所有结果组合输出。所以map和reduce都是并行运行的，从而能够处理一般服务器不能处理的大数据量处理问题。</p>
<p>实际存在许多不安全因素：</p>
<p>1.不可信的Map函数</p>
<p>2.缺乏用户及服务器安全认证机制和访问控制机制</p>
<p>3.缺乏传输以及存储加密</p>
<h5 id="2）非关系型数据存储安全"><a href="#2）非关系型数据存储安全" class="headerlink" title="2）非关系型数据存储安全"></a>2）非关系型数据存储安全</h5><p>NoSQL是一种非关系型数据库。</p>
<p>1.薄弱的验证机制</p>
<p>2.低效的鉴权机制</p>
<p>3.NoSQL易受各类注入攻击</p>
<p>4.事务处理的一致性较弱</p>
<h4 id="5-2影响数据安全的要素"><a href="#5-2影响数据安全的要素" class="headerlink" title="5.2影响数据安全的要素"></a>5.2影响数据安全的要素</h4><h5 id="1）数据来源的可靠性"><a href="#1）数据来源的可靠性" class="headerlink" title="1）数据来源的可靠性"></a>1）数据来源的可靠性</h5><p>1.伪造或刻意制造的数据</p>
<p>2.数据在传播过程中的逐步失真或被人为破坏</p>
<p>3.元数据可能被伪造和修改</p>
<h5 id="2）数据泄露"><a href="#2）数据泄露" class="headerlink" title="2）数据泄露"></a>2）数据泄露</h5><p>略</p>
<h5 id="3）数据挖掘和分析中的隐私问题"><a href="#3）数据挖掘和分析中的隐私问题" class="headerlink" title="3）数据挖掘和分析中的隐私问题"></a>3）数据挖掘和分析中的隐私问题</h5><p>略</p>
<h4 id="5-3大数据架构的安全测评"><a href="#5-3大数据架构的安全测评" class="headerlink" title="5.3大数据架构的安全测评"></a>5.3大数据架构的安全测评</h4><h5 id="分布式计算框架的安全测评"><a href="#分布式计算框架的安全测评" class="headerlink" title="分布式计算框架的安全测评"></a>分布式计算框架的安全测评</h5><p>在用户使用mapreduce框架中常出现的危险类型有以下几种：</p>
<p>1.一个故障的map工作节点产生了错误结果，使得最终的数据分析结论不符合事实。</p>
<p>2.黑客利用自己伪造的map函数对云架构实施攻击。</p>
<p>3.一个伪造的Map节点被加入集群中，发生大量重复数据，并不断引入新的伪造map节点，对数据分析产生影响。</p>
<p>针对以上所述的危险，需要从两个维度上保证mapreduce的安全；确保mapper的可信度和确保数据的可信性。确保mapper的可信度可以从建立信任来实现。建立信任包括两个步骤：一是建立初始行信任；二是在初始认证后，周期性检查每个worker节点的安全属性和与预先确定的安全策略是否一致。</p>
<p>确保数据可信度可以通过访问控制来实现。</p>
<p>hadoop提供了两种安全机制：simple和Kerberos</p>
<p>下面以Hadoop中的安全配置为例，说明mapreduce的安全测评过程<br>。</p>
<p>1.检查身份认证和授权配置</p>
<p>2.检查调度器配置</p>
<p>3.检查作业队列权限配置</p>
<p>4.检查DFS permission配置</p>
<h5 id="非关系型数据库的安全测评"><a href="#非关系型数据库的安全测评" class="headerlink" title="非关系型数据库的安全测评"></a>非关系型数据库的安全测评</h5><p>针对NoSQL数据库，HBase</p>
<p>1.检查身份认证配置</p>
<p>2.检查接口调用的安全配置</p>
<p>3.检查访问控制</p>
<h4 id="5-4-数据的安全测评"><a href="#5-4-数据的安全测评" class="headerlink" title="5.4 数据的安全测评"></a>5.4 数据的安全测评</h4><h5 id="5-4-1数据来源的安全测评"><a href="#5-4-1数据来源的安全测评" class="headerlink" title="5.4.1数据来源的安全测评"></a>5.4.1数据来源的安全测评</h5><p>1.恶意数据输入的预防机制及其测评</p>
<p>2.基于数据源技术的数据可信度评估</p>
<h5 id="5-4-2隐私保护程度的测评"><a href="#5-4-2隐私保护程度的测评" class="headerlink" title="5.4.2隐私保护程度的测评"></a>5.4.2隐私保护程度的测评</h5><p>1.数据去隐私处理效果的测评</p>
<p>2.访问控制机制的测评</p>
<p>3.对计算结果隐私程度的测评</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/26/LSTM-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/26/LSTM-1/" class="post-title-link" itemprop="url">LSTM.1</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-26 13:04:08" itemprop="dateCreated datePublished" datetime="2020-01-26T13:04:08+08:00">2020-01-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-08 15:17:28" itemprop="dateModified" datetime="2020-02-08T15:17:28+08:00">2020-02-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="用LSTM做时间序列测试的一个例子"><a href="#用LSTM做时间序列测试的一个例子" class="headerlink" title="用LSTM做时间序列测试的一个例子"></a>用LSTM做时间序列测试的一个例子</h2><h4 id="问题：航班乘客预测"><a href="#问题：航班乘客预测" class="headerlink" title="问题：航班乘客预测"></a>问题：航班乘客预测</h4><h4 id="数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000"><a href="#数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000" class="headerlink" title="数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000"></a>数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000</h4><h4 id="目标：预测国际航班未来一个月的乘客数"><a href="#目标：预测国际航班未来一个月的乘客数" class="headerlink" title="目标：预测国际航班未来一个月的乘客数"></a>目标：预测国际航班未来一个月的乘客数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from pandas import read_csv</span><br><span class="line">import math</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Dense</span><br><span class="line">from keras.layers import LSTM</span><br><span class="line">from sklearn.preprocessing  import MinMaxScaler</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br></pre></td></tr></table></figure>
<h6 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataframe&#x3D;read_csv(&#39;international-airline-passengers.csv&#39;,usecols&#x3D;[1],engine&#x3D;&#39;python&#39;,skipfooter&#x3D;3)</span><br><span class="line">dataset&#x3D;dataframe.values #取y轴</span><br><span class="line">#将整形变为float</span><br><span class="line">dataset&#x3D;dataset.astype(&#39;float32&#39;)</span><br><span class="line">plt.plot(dataset)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h6 id="需要把数据转换一下"><a href="#需要把数据转换一下" class="headerlink" title="需要把数据转换一下"></a>需要把数据转换一下</h6><h6 id="将一列变为两列，第一列是t月的乘客数，第二列是t-1月的乘客数。look-back是预测下一步所需要的time-steps"><a href="#将一列变为两列，第一列是t月的乘客数，第二列是t-1月的乘客数。look-back是预测下一步所需要的time-steps" class="headerlink" title="将一列变为两列，第一列是t月的乘客数，第二列是t+1月的乘客数。look_back是预测下一步所需要的time_steps"></a>将一列变为两列，第一列是t月的乘客数，第二列是t+1月的乘客数。look_back是预测下一步所需要的time_steps</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def create_dataset(dataset,look_back&#x3D;1):</span><br><span class="line">    datax,datay&#x3D;[],[]</span><br><span class="line">    for i in range(len(dataset)-look_back-1):</span><br><span class="line">         a&#x3D;dataset[i:(i+look_back),0]</span><br><span class="line">         datax.append(a)</span><br><span class="line">         datay.append(dataset[i+look_back,0])</span><br><span class="line">    return numpy.array(datax),numpy.array(datay)</span><br><span class="line">#datax是输入数据，datay是对应的输出数据</span><br><span class="line">numpy.random.seed(7)</span><br></pre></td></tr></table></figure>
<h6 id="当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感"><a href="#当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感" class="headerlink" title="当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感"></a>当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感</h6><h6 id="设定67-是训练数据，余下是测试数据"><a href="#设定67-是训练数据，余下是测试数据" class="headerlink" title="设定67%是训练数据，余下是测试数据"></a>设定67%是训练数据，余下是测试数据</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#正则化数据</span><br><span class="line">scaler&#x3D;MinMaxScaler(feature_range&#x3D;(0,1))</span><br><span class="line">dataset&#x3D;scaler.fit_transform(dataset)</span><br><span class="line">#分成训练数据和测试数据,即训练集和测试集是同一个时间序列的不同部分</span><br><span class="line">train_size&#x3D;int(len(dataset)*0.67)</span><br><span class="line">test_size&#x3D;len(dataset)-train_size</span><br><span class="line">train,test&#x3D;dataset[0:train_size,:],dataset[train_size:len(dataset),:]</span><br></pre></td></tr></table></figure>
<h6 id="输入为X-t时，输出为Y-t-1时的数据，此时look-back为1"><a href="#输入为X-t时，输出为Y-t-1时的数据，此时look-back为1" class="headerlink" title="输入为X=t时，输出为Y=t+1时的数据，此时look_back为1"></a>输入为X=t时，输出为Y=t+1时的数据，此时look_back为1</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">look_back&#x3D;1</span><br><span class="line">#此时trainx和testx的维度为[samples,features]</span><br><span class="line">trainx,trainy&#x3D;create_dataset(train,look_back)</span><br><span class="line">testx,testy&#x3D;creat_dataset(test,look_back)</span><br></pre></td></tr></table></figure>
<h6 id="由于投入LSTM的X需要这样的结构：-samples-look-back-features-所以交换一下"><a href="#由于投入LSTM的X需要这样的结构：-samples-look-back-features-所以交换一下" class="headerlink" title="由于投入LSTM的X需要这样的结构：[samples,look_back,features],所以交换一下"></a>由于投入LSTM的X需要这样的结构：[samples,look_back,features],所以交换一下</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainx&#x3D;numpy.reshape(trainx,(trainx.shape[0],1,trainx.shape[1]))</span><br><span class="line">testx&#x3D;numpy.reshape(testx,(testx.shape[0],1,testx.shape[1]))</span><br></pre></td></tr></table></figure>
<h6 id="建立LSTM模型"><a href="#建立LSTM模型" class="headerlink" title="建立LSTM模型"></a>建立LSTM模型</h6><h6 id="输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch-size为1"><a href="#输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch-size为1" class="headerlink" title="输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch size为1"></a>输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch size为1</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model&#x3D;Sequential()</span><br><span class="line">model.add(LSTM(4,input_shape&#x3D;(1,look_back))</span><br><span class="line">model.add(Dense(1))</span><br><span class="line">model.compile(loss&#x3D;&#39;mean_squared_error&#39;,optimizer&#x3D;&#39;adam&#39;)</span><br><span class="line">model.fit(trainx,trainy,epochs&#x3D;100,batch_size&#x3D;1,verbose&#x3D;2)</span><br></pre></td></tr></table></figure>
<h6 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainpredict&#x3D;model.predict(trainx)</span><br><span class="line">trainpredict&#x3D;model.predict(testx)</span><br></pre></td></tr></table></figure>
<h6 id="计算误差之前要把预测数据转化为同一单位"><a href="#计算误差之前要把预测数据转化为同一单位" class="headerlink" title="计算误差之前要把预测数据转化为同一单位"></a>计算误差之前要把预测数据转化为同一单位</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trainpredict&#x3D;scaler.inverse_transform(trainpredict)</span><br><span class="line">trainy&#x3D;scaler.inverse_transform([trainy])</span><br><span class="line">testpredict&#x3D;scaler.inverse_transform(testpredict)</span><br><span class="line">testy&#x3D;scaler.inverse_transform([testy])</span><br></pre></td></tr></table></figure>
<h6 id="计算mean-squared-error"><a href="#计算mean-squared-error" class="headerlink" title="计算mean squared error"></a>计算mean squared error</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trainscore&#x3D;math.sqrt(mean_squared_error(trainy[0],trainpredict[:,0&#125;))</span><br><span class="line">print(&#39;train score:%.2f RMSE&#39;%(trainscore))</span><br><span class="line">testscore&#x3D;math.sqrt(mean_squared_error(testy[0],testpredict[:,0]))</span><br><span class="line">print(&#39;test score:%.2f RMSE&#39;%(testscore))</span><br></pre></td></tr></table></figure>
<h6 id="画出结果"><a href="#画出结果" class="headerlink" title="画出结果"></a>画出结果</h6><h6 id="蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值"><a href="#蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值" class="headerlink" title="蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值"></a>蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">trainpredictplot &#x3D; numpy.empty_like(dataset)</span><br><span class="line">trainpredictplot[:,:]&#x3D;numpy.nan</span><br><span class="line">trainpredictplot[look_back:len(trainpredict)+look_back,:]&#x3D;trainpredict</span><br><span class="line"></span><br><span class="line">testpredictplot&#x3D;numpy.empty_like(dataset)</span><br><span class="line">testpredictplot[:,:]&#x3D;numpy.nan</span><br><span class="line">testpredictplot[len(trainpredict)+(look_back*2)+1:len(dataset)-1,:]&#x3D;testpredict</span><br><span class="line"></span><br><span class="line">plt.plot(scaler.inverse_transform(dataset))</span><br><span class="line">plt.plot(trainpredictplot)</span><br><span class="line">plt.plot(testpredictplot)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


































      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/23/newpapername/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="annen's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/23/newpapername/" class="post-title-link" itemprop="url">newpapername</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-23 11:50:16 / 修改时间：11:50:17" itemprop="dateCreated datePublished" datetime="2020-01-23T11:50:16+08:00">2020-01-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ah</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ah</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
