<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://annen-stack.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="anne&#39;s blog">
<meta property="og:url" content="https://annen-stack.github.io/index.html">
<meta property="og:site_name" content="anne&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="ah">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://annen-stack.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>anne's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">anne's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/26/%E5%9F%BA%E4%BA%8Ekeras%E7%9A%84LSTM%E5%A4%9A%E5%8F%98%E9%87%8F%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="anne's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/26/%E5%9F%BA%E4%BA%8Ekeras%E7%9A%84LSTM%E5%A4%9A%E5%8F%98%E9%87%8F%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B/" class="post-title-link" itemprop="url">基于keras的LSTM多变量时间序列预测</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-26 15:29:28 / 修改时间：15:30:01" itemprop="dateCreated datePublished" datetime="2020-01-26T15:29:28+08:00">2020-01-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>利用深度学习库keras搭建LSTM模型来处理多个变量的时间序列预测问题</p>
<h5 id="1-如何将原始数据转化为适合处理时序预测问题的数据格式"><a href="#1-如何将原始数据转化为适合处理时序预测问题的数据格式" class="headerlink" title="1.如何将原始数据转化为适合处理时序预测问题的数据格式"></a>1.如何将原始数据转化为适合处理时序预测问题的数据格式</h5><h5 id="2-如何准备数据并搭建LSTM来处理时序预测问题"><a href="#2-如何准备数据并搭建LSTM来处理时序预测问题" class="headerlink" title="2.如何准备数据并搭建LSTM来处理时序预测问题"></a>2.如何准备数据并搭建LSTM来处理时序预测问题</h5><h5 id="3-如何利用模型预测"><a href="#3-如何利用模型预测" class="headerlink" title="3.如何利用模型预测"></a>3.如何利用模型预测</h5><h3 id="1-空气污染预测"><a href="#1-空气污染预测" class="headerlink" title="1.空气污染预测"></a>1.空气污染预测</h3><p>数据集包括行数、日期（年；月；日；小时）、PM2.5浓度、露点、温度、大气压、风向、风速、累计小时雪景、累计小时鱼量</p>
<h3 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h3><p>粗略的观察数据集，需要删除最开始的24小时的PM2.5,对于其他时刻少量的缺省值利用pandas中的fillna填充；同时需要整合日期数据，使其作为pandas中的索引。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from pandas import read_csv</span><br><span class="line">from datetime import datetime</span><br><span class="line"># load data</span><br><span class="line">def parse(x):</span><br><span class="line">    return datetime.strptime(x, &#39;%Y %m %d %H&#39;)</span><br><span class="line">dataset &#x3D; read_csv(&#39;raw.csv&#39;,  parse_dates &#x3D; [[&#39;year&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]], index_col&#x3D;0, date_parser&#x3D;parse)</span><br><span class="line">dataset.drop(&#39;No&#39;, axis&#x3D;1, inplace&#x3D;True)</span><br><span class="line"># manually specify column names</span><br><span class="line">dataset.columns &#x3D; [&#39;pollution&#39;, &#39;dew&#39;, &#39;temp&#39;, &#39;press&#39;, &#39;wnd_dir&#39;, &#39;wnd_spd&#39;, &#39;snow&#39;, &#39;rain&#39;]</span><br><span class="line">dataset.index.name &#x3D; &#39;date&#39;</span><br><span class="line"># mark all NA values with 0</span><br><span class="line">dataset[&#39;pollution&#39;].fillna(0, inplace&#x3D;True)</span><br><span class="line"># drop the first 24 hours</span><br><span class="line">dataset &#x3D; dataset[24:]</span><br><span class="line"># summarize first 5 rows</span><br><span class="line">print(dataset.head(5))</span><br><span class="line"># save to file</span><br><span class="line">dataset.to_csv(&#39;pollution.csv&#39;)</span><br></pre></td></tr></table></figure>
<p>将参数绘制图像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from pandas import read_csv</span><br><span class="line">from matplotlib import pyplot</span><br><span class="line"># load dataset</span><br><span class="line">dataset &#x3D; read_csv(&#39;pollution.csv&#39;, header&#x3D;0, index_col&#x3D;0)</span><br><span class="line">values &#x3D; dataset.values</span><br><span class="line"># specify columns to plot</span><br><span class="line">groups &#x3D; [0, 1, 2, 3, 5, 6, 7]</span><br><span class="line">i &#x3D; 1</span><br><span class="line"># plot each column</span><br><span class="line">pyplot.figure()</span><br><span class="line">for group in groups:</span><br><span class="line">    pyplot.subplot(len(groups), 1, i)</span><br><span class="line">    pyplot.plot(values[:, group])</span><br><span class="line">    pyplot.title(dataset.columns[group], y&#x3D;0.5, loc&#x3D;&#39;right&#39;)</span><br><span class="line">    i +&#x3D; 1</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<h3 id="3-多变量LSTM预测模型"><a href="#3-多变量LSTM预测模型" class="headerlink" title="3.多变量LSTM预测模型"></a>3.多变量LSTM预测模型</h3><p>　下面代码中首先加载“pollution.csv”文件，并利用sklearn的预处理模块对类别特征“风向”进行编码，当然也可以对该特征进行one-hot编码。<br>　　接着对所有的特征进行归一化处理，然后将数据集转化为有监督学习问题，同时将需要预测的当前时刻（t）的天气条件特征移除，完整代码如下：
　　</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># convert series to supervised learning</span><br><span class="line">def series_to_supervised(data, n_in&#x3D;1, n_out&#x3D;1, dropnan&#x3D;True):</span><br><span class="line">    n_vars &#x3D; 1 if type(data) is list else data.shape[1]</span><br><span class="line">    df &#x3D; DataFrame(data)</span><br><span class="line">    cols, names &#x3D; list(), list()</span><br><span class="line">    # input sequence (t-n, ... t-1)</span><br><span class="line">    for i in range(n_in, 0, -1):</span><br><span class="line">        cols.append(df.shift(i))</span><br><span class="line">        names +&#x3D; [(&#39;var%d(t-%d)&#39; % (j+1, i)) for j in range(n_vars)]</span><br><span class="line">    # forecast sequence (t, t+1, ... t+n)</span><br><span class="line">    for i in range(0, n_out):</span><br><span class="line">        cols.append(df.shift(-i))</span><br><span class="line">        if i &#x3D;&#x3D; 0:</span><br><span class="line">            names +&#x3D; [(&#39;var%d(t)&#39; % (j+1)) for j in range(n_vars)]</span><br><span class="line">        else:</span><br><span class="line">            names +&#x3D; [(&#39;var%d(t+%d)&#39; % (j+1, i)) for j in range(n_vars)]</span><br><span class="line">    # put it all together</span><br><span class="line">    agg &#x3D; concat(cols, axis&#x3D;1)</span><br><span class="line">    agg.columns &#x3D; names</span><br><span class="line">    # drop rows with NaN values</span><br><span class="line">    if dropnan:</span><br><span class="line">        agg.dropna(inplace&#x3D;True)</span><br><span class="line">    return agg</span><br><span class="line"></span><br><span class="line"># load dataset</span><br><span class="line">dataset &#x3D; read_csv(&#39;pollution.csv&#39;, header&#x3D;0, index_col&#x3D;0)</span><br><span class="line">values &#x3D; dataset.values</span><br><span class="line"># integer encode direction</span><br><span class="line">encoder &#x3D; LabelEncoder()</span><br><span class="line">values[:,4] &#x3D; encoder.fit_transform(values[:,4])</span><br><span class="line"># ensure all data is float</span><br><span class="line">values &#x3D; values.astype(&#39;float32&#39;)</span><br><span class="line"># normalize features</span><br><span class="line">scaler &#x3D; MinMaxScaler(feature_range&#x3D;(0, 1))</span><br><span class="line">scaled &#x3D; scaler.fit_transform(values)</span><br><span class="line"># frame as supervised learning</span><br><span class="line">reframed &#x3D; series_to_supervised(scaled, 1, 1)</span><br><span class="line"># drop columns we don&#39;t want to predict</span><br><span class="line">reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis&#x3D;1, inplace&#x3D;True)</span><br><span class="line">print(reframed.head())</span><br></pre></td></tr></table></figure>
<p>构造模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># split into train and test sets</span><br><span class="line">values &#x3D; reframed.values</span><br><span class="line">n_train_hours &#x3D; 365 * 24</span><br><span class="line">train &#x3D; values[:n_train_hours, :]</span><br><span class="line">test &#x3D; values[n_train_hours:, :]</span><br><span class="line"># split into input and outputs</span><br><span class="line">train_X, train_y &#x3D; train[:, :-1], train[:, -1]</span><br><span class="line">test_X, test_y &#x3D; test[:, :-1], test[:, -1]</span><br><span class="line"># reshape input to be 3D [samples, timesteps, features]</span><br><span class="line">train_X &#x3D; train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))</span><br><span class="line">test_X &#x3D; test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))</span><br><span class="line">print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)</span><br></pre></td></tr></table></figure>
<p>现在可以搭建LSTM模型了。 </p>
<p>　　LSTM模型中，隐藏层有50个神经元，输出层1个神经元（回归问题），输入变量是一个时间步（t-1）的特征，损失函数采用Mean Absolute Error(MAE)，优化算法采用Adam，模型采用50个epochs并且每个batch的大小为72。<br>　　<br>　　最后，在fit()函数中设置validation_data参数，记录训练集和测试集的损失，并在完成训练和测试后绘制损失图。
　　</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># design network</span><br><span class="line">model &#x3D; Sequential()</span><br><span class="line">model.add(LSTM(50, input_shape&#x3D;(train_X.shape[1], train_X.shape[2])))</span><br><span class="line">model.add(Dense(1))</span><br><span class="line">model.compile(loss&#x3D;&#39;mae&#39;, optimizer&#x3D;&#39;adam&#39;)</span><br><span class="line"># fit network</span><br><span class="line">history &#x3D; model.fit(train_X, train_y, epochs&#x3D;50, batch_size&#x3D;72, validation_data&#x3D;(test_X, test_y), verbose&#x3D;2, shuffle&#x3D;False)</span><br><span class="line"># plot history</span><br><span class="line">pyplot.plot(history.history[&#39;loss&#39;], label&#x3D;&#39;train&#39;)</span><br><span class="line">pyplot.plot(history.history[&#39;val_loss&#39;], label&#x3D;&#39;test&#39;)</span><br><span class="line">pyplot.legend()</span><br><span class="line">pyplot.show()</span><br><span class="line"></span><br><span class="line"># design network</span><br><span class="line">model &#x3D; Sequential()</span><br><span class="line">model.add(LSTM(50, input_shape&#x3D;(train_X.shape[1], train_X.shape[2])))</span><br><span class="line">model.add(Dense(1))</span><br><span class="line">model.compile(loss&#x3D;&#39;mae&#39;, optimizer&#x3D;&#39;adam&#39;)</span><br><span class="line"># fit network</span><br><span class="line">history &#x3D; model.fit(train_X, train_y, epochs&#x3D;50, batch_size&#x3D;72, validation_data&#x3D;(test_X, test_y), verbose&#x3D;2, shuffle&#x3D;False)</span><br><span class="line"># plot history</span><br><span class="line">pyplot.plot(history.history[&#39;loss&#39;], label&#x3D;&#39;train&#39;)</span><br><span class="line">pyplot.plot(history.history[&#39;val_loss&#39;], label&#x3D;&#39;test&#39;)</span><br><span class="line">pyplot.legend()</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p>模型评估</p>
<p>　接下里我们对模型效果进行评估。<br>　<br>　　值得注意的是：需要将预测结果和部分测试集数据组合然后进行比例反转，同时也需要将测试集上的预期值也进行比例转换。 </p>
<p>　　至于在这里为什么进行比例反转，是因为我们将原始数据进行了预处理（连同输出值y），此时的误差损失计算是在处理之后的数据上进行的，为了计算在原始比例上的误差需要将数据进行转化。同时笔者有个小Tips：就是反转时的矩阵大小一定要和原来的大小（shape）完全相同，否则就会报错。<br>　　<br>　通过以上处理之后，再结合RMSE（均方根误差）计算损失。
　</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># make a prediction</span><br><span class="line">yhat &#x3D; model.predict(test_X)</span><br><span class="line">test_X &#x3D; test_X.reshape((test_X.shape[0], test_X.shape[2]))</span><br><span class="line"># invert scaling for forecast</span><br><span class="line">inv_yhat &#x3D; concatenate((yhat, test_X[:, 1:]), axis&#x3D;1)</span><br><span class="line">inv_yhat &#x3D; scaler.inverse_transform(inv_yhat)</span><br><span class="line">inv_yhat &#x3D; inv_yhat[:,0]</span><br><span class="line"># invert scaling for actual</span><br><span class="line">test_y &#x3D; test_y.reshape((len(test_y), 1))</span><br><span class="line">inv_y &#x3D; concatenate((test_y, test_X[:, 1:]), axis&#x3D;1)</span><br><span class="line">inv_y &#x3D; scaler.inverse_transform(inv_y)</span><br><span class="line">inv_y &#x3D; inv_y[:,0]</span><br><span class="line"># calculate RMSE</span><br><span class="line">rmse &#x3D; sqrt(mean_squared_error(inv_y, inv_yhat))</span><br><span class="line">print(&#39;Test RMSE: %.3f&#39; % rmse)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%8B%E8%AF%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="anne's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%8B%E8%AF%95/" class="post-title-link" itemprop="url">大数据测试</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-26 13:53:34 / 修改时间：13:53:55" itemprop="dateCreated datePublished" datetime="2020-01-26T13:53:34+08:00">2020-01-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一、绪论："><a href="#一、绪论：" class="headerlink" title="一、绪论："></a>一、绪论：</h2><p> 大数据是大容量、高速率、多形态的信息资产，且需要成本效益、信息处理来增加洞察力和决策创新形式。大数据是指大小超出了典型数据库软件工具收集、存储、管理和分析能力的数据集。</p>
<p>大数据分析框架测试、算法质量测试、性能测试、大数据安全和隐私软件测试的经典定义：为发现软件错误，而运行软件的活动。</p>
<p>基本思路：根据软件需求规格说明书，执行软件操作和输入数据，依据软件实际输出结果和预期输出结果来评判软件是否满足规格的要求</p>
<p>本书以Hadoop为主线:底层支撑框架层聚焦于单元测试和框架基准测试；基本算法中涵盖了聚类、分类及其个性化推荐；应用层中，介绍了其性能测试中的若干问题，阐述了数据集的设计与分析；最后讨论了大数据的安全和隐私问题。</p>
<h4 id="大数据特征"><a href="#大数据特征" class="headerlink" title="大数据特征"></a>大数据特征</h4><p>数据类型繁多；处理速度快；数据体量大；数据价值；真实性</p>
<h4 id="大数据的过程模型"><a href="#大数据的过程模型" class="headerlink" title="大数据的过程模型"></a>大数据的过程模型</h4><p>数据源；数据收集及录入；数据过滤及分类；数据分类/建模/预测；数据交付及可视化；消费者的数据分析及应用</p>
<h4 id="大数据相关标准"><a href="#大数据相关标准" class="headerlink" title="大数据相关标准"></a>大数据相关标准</h4><p>大数据相关的标准可分为两大类：基础类和技术类。基础类包括大数据平台技术参考架构、大数据总体技术要求、大数据标准化指南。技术类可分为数据采集、数据存储、数据处理和分析、数据管理。</p>
<p>1.数据采集    数据抽取和预处理等相关规范</p>
<p>2.数据存储     各种类型数据的存储和访问接口规范。</p>
<p>3.数据处理和分析    </p>
<p> 4.数据管理   针对数据的源数据管理、质量管理及数据管理接口规范</p>
<h4 id="大数据的应用"><a href="#大数据的应用" class="headerlink" title="大数据的应用"></a>大数据的应用</h4><p> 趋势预测；疫情分析；消费行为分析；智慧金融；智慧金融；精确营销; 舆情分析;</p>
<h4 id="大数据引起的软件变化"><a href="#大数据引起的软件变化" class="headerlink" title="大数据引起的软件变化"></a>大数据引起的软件变化</h4><p>传统的软件架构无法满足大数据处理的要求；大数据软件处理的结果是未知的；大数据的软件思维模式发生逆转。</p>
<h4 id="软件测试的新挑战"><a href="#软件测试的新挑战" class="headerlink" title="软件测试的新挑战"></a>软件测试的新挑战</h4><p>测试ORACLE问题： 软件测试的基本前提是在确定的输入下，存在确定的输出。测试要将软件运行的实际结果和预期的结果相比较，从而得出软件运行正确与否。</p>
<p>测试能力问题：测试结果的判定问题：在大数据的分析背景下，典型的应用场景不存在确定的输出，大数据的分析的准确性很大程度上依赖于数据的输入和数据的分布特性。</p>
<p>隐私问题：（略）</p>
<h2 id="面向大数据框架的测评"><a href="#面向大数据框架的测评" class="headerlink" title="面向大数据框架的测评"></a>面向大数据框架的测评</h2><p>本章将介绍Hadoop大数据框架的单元测试、大数据的数据清洗、数据质量评估框架以及大数据的基准性能测试技术。</p>
<h4 id="2-1大数据的数据处理流程"><a href="#2-1大数据的数据处理流程" class="headerlink" title="2.1大数据的数据处理流程"></a>2.1大数据的数据处理流程</h4><p>在处理大数据之前需要对来自不同数据源的数据进行数据处理，包括数据抽取和数据集成。通过数据抽取和数据集成操作提取出关系和实体，对其进行关联和聚类的相关操作后，采用统一定义的结构来存储这些数据。数据清洗在数据集成与数据抽取之前，保证数据质量与可行性。</p>
<h4 id="2-2面向数据质量的测评"><a href="#2-2面向数据质量的测评" class="headerlink" title="2.2面向数据质量的测评"></a>2.2面向数据质量的测评</h4><h5 id="数据质量的定义"><a href="#数据质量的定义" class="headerlink" title="数据质量的定义"></a>数据质量的定义</h5><p>数据本身质量：数据真实性、数据完备性、数据自治性。</p>
<p>数据过程质量：数据使用质量、数据存储质量、数据传输质量。</p>
<h5 id="数据质量问题的分类"><a href="#数据质量问题的分类" class="headerlink" title="数据质量问题的分类"></a>数据质量问题的分类</h5><p>略</p>
<h5 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h5><p>1.数据清理</p>
<p>不符合要求的数据：数据缺失；数据错误；数据重复（mapreduce去重）</p>
<p>2.数据集成/数据变换</p>
<p>数据集成是指从逻辑上或者物理上将来源或格式以及特点性质不同的数据有机地集中起来，为数据挖掘提供完整的数据源。</p>
<p>数据集成问题分类：数据表链接不匹配；冗余；数据值冲突。</p>
<p>数据变换：属性的数据类型转换；属性构造；数据离散化；数据标准化。</p>
<p>3.数据规约</p>
<p>可以获得数据集的简化表示；属性选择、实例选择。</p>
<h5 id="数据质量测评"><a href="#数据质量测评" class="headerlink" title="数据质量测评"></a>数据质量测评</h5><p>1.数据清洗框架和工具</p>
<p>数据清洗：映射、匹配、聚集、合并、跟踪。</p>
<p>2.数据清洗评估</p>
<p>相关性；准确性；及时性；完整性；一致性；</p>
<h4 id="2-3分布式数据模型及测试"><a href="#2-3分布式数据模型及测试" class="headerlink" title="2.3分布式数据模型及测试"></a>2.3分布式数据模型及测试</h4><h5 id="框架："><a href="#框架：" class="headerlink" title="框架："></a>框架：</h5><p>Hadoop的核心是HDFS和MapReduce，为用户提供了系统底层透明的分布式基础框架。</p>
<p>mapreduce:分布式数据处理模型和执行环境，运用于大规模的通用计算机集群。</p>
<p>HDFS：Hadoop的分布式文件系统，运用于大规模的通用计算机集群。</p>
<p>HBase:分布式按列存储的数据，使用HDFS作为底层存储，同时支持MapReduce的批量式计算和点查询。</p>
<p>Hive:分布式、按列存储的数据仓库。</p>
<h5 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h5><p>最底层的两个抽象实体，分别是HDFS和MapReduce。</p>
<h5 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h5><p>MRUnit是针对MapReduce的单元测试框架；针对不同的测试对象，MRUnit使用以下几种Driver:</p>
<p>MapDriver   测试单独的Map</p>
<p>ReduceDriver  测试单独的Reduce</p>
<p>MapReduce Driver 将Map与Reduce结合起来测试</p>
<p>从Apache下载MRUnit最新版的jar包，并将jar包添加到hadoop的IDE Classpath 路径中。</p>
<h5 id="测试代码："><a href="#测试代码：" class="headerlink" title="测试代码："></a>测试代码：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public class SMSCDRMapperReducerTest&#123;</span><br><span class="line">    MapDriver&lt;LongWritable,Text,Text,IntWritable&gt;mapDriver; </span><br><span class="line">    ReduceDriver&lt;Text,IntWritable,Text,IntWritable&gt;reduceDriver;</span><br><span class="line">    MapReduceDriver&lt;LongWritable,Text,Text,IntWritable,Text,IntWritable&gt;mapReduceDriver;</span><br><span class="line">    @Before</span><br><span class="line">       public void setUp()&#123;</span><br><span class="line">           SMSCDRMapper mapper &#x3D; new SMSCDRMapper();</span><br><span class="line">           SMSCDReducer reducer &#x3D; new SMSCDRReducer();</span><br><span class="line">           mapReduceDriver &#x3D; MapReduceDriver.newMapReduceDriver(mapper,reducer);</span><br><span class="line">       &#125;</span><br><span class="line">   @Text    </span><br><span class="line">       public void testMapReduce()&#123;</span><br><span class="line">               Text mapInputValue1 &#x3D; new Text(&quot;595877;1;7585458855;4441417;5&quot;)</span><br><span class="line">               Text mapInputValue2 &#x3D; new Text(&quot;735856;1;5498749558;8478941;3&quot;)</span><br><span class="line">               mapReduceDriver.withInput(new LongWritable(1),mapInputValue1);</span><br><span class="line">               mapReduceDriver.withInput(new LongWritable(1),mapInputValue2);</span><br><span class="line">               mapReduceDriver.addOutput(new Text(&quot;5&quot;),new IntWritable(1));</span><br><span class="line">               mapReduceDriver.addOutput(new Text(&quot;3&quot;),new IntWritable(1));</span><br><span class="line">               maReduceDriver.runTest();</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-4大数据的基准测试"><a href="#2-4大数据的基准测试" class="headerlink" title="2.4大数据的基准测试"></a>2.4大数据的基准测试</h4><p>基准测试是一种测量和评估软件性能指标的典型活动。可以在某个时刻通过基准测试建立一个已知的性能水平，当系统的软硬件环境发生变化后再进行一次基准测试，以确定那些变化对性能的影响。</p>
<h5 id="2-4-1测试方法"><a href="#2-4-1测试方法" class="headerlink" title="2.4.1测试方法"></a>2.4.1测试方法</h5><h6 id="1）测试步骤"><a href="#1）测试步骤" class="headerlink" title="1）测试步骤"></a>1）测试步骤</h6><p>通常是在系统上运行一系列的测试程序，并把性能计数器的结果保存起来，这些结果称为“性能指标”。</p>
<h6 id="2）测试工具集"><a href="#2）测试工具集" class="headerlink" title="2）测试工具集"></a>2）测试工具集</h6><p>包括工业界、科研界提出的测试工具集和大数据提供的测试基准。</p>
<p>具体包括：</p>
<p>1.BigBench</p>
<p>2.hadoop自带的测试基准，这些程序可以从多个角度对Hadoop进行测试，TestDFSIO,mrbench和nnbench是三个广泛使用的测试。</p>
<p>TestDFSIO用于测试HDFS的IO性能。</p>
<p>nnbench用于测试NameNode负载。</p>
<p>mrbench会多次重复执行一个小作业，用于检查在机群上小作业的运行是否可以重复以及运行是否高效。</p>
<p>3.HBase系统本身提供了性能测试工具。</p>
<h6 id="3）数据准备"><a href="#3）数据准备" class="headerlink" title="3）数据准备"></a>3）数据准备</h6><p>数据基准测试中常用的数据生成工具包括HiBench与BDGS。</p>
<p>HiBench的容量是扩展的，可以生成非结构的文本数据类型并支持hadoop hive。BDGS在保留原始数据特性的基础上以小规模的真实数据生成大规模的数据。</p>
<p>并行数据生成框架是一种适应性很强的数据生成工具，可以在短时间内生成大量的关系数据。PDGF利用并行随机数发生器来生成独立的相关值。</p>
<h5 id="2-4-2测试内容"><a href="#2-4-2测试内容" class="headerlink" title="2.4.2测试内容"></a>2.4.2测试内容</h5><p>下面给出不同的测试工具集包括的测试内容：</p>
<p>1.big data bench from uc berkeley<br>redshift \hive\shark\impala</p>
<p>2.bigdatabench</p>
<p>3.hibench基准测试</p>
<p>4.hadoop基准测试</p>
<p>TestDFSIO的测试步骤：</p>
<p>用法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Usage: TestDFSIO[genericOptions]   -read|-write|-append|-clean[-nrFiles N]</span><br></pre></td></tr></table></figure>
<p>命令行：</p>
<p>例子将往HDFS中写入10个1000MB的文件： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop - *test*.jar TestDFSIO -read -nrFiles 10  -fileSize 1000</span><br></pre></td></tr></table></figure>
<p>nnbench：用于测试NameNode的负载，它会生成很多与HDFRS相关的请求，给NameNode施加压力。<br>例如，使用12个mapper和6个reducer来创建1000个文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop - *test*.jar nnbench\</span><br><span class="line">   -operation create_write -maps 12 -reduces 6 -blockSize 1\</span><br><span class="line">   -bytesToWrite 0 -numberOfFiles 1000 -replicationFactorPerFiles 3\</span><br><span class="line">   -readFileAfterOpen true -baseDir&#x2F;benchmarks&#x2F;NNBench - &#39;hostname -s&#39;</span><br></pre></td></tr></table></figure>
<p>mrbench会多次重复执行一个小作业，用于检查在机群上小作业的运行是否可以重复以及运行是否高效。<br>例如，运行一个小作业50次。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop - *test*.jar mrbench -numRuns 50</span><br></pre></td></tr></table></figure>
<p>Terasort是测试Hadoop的一个有效的排序程序。通过Hadoop自带的Terasort排序程序，测试不同的Map任务和Reduce 任务数量，对hadoop性能的影响。<br>一个完整的Terasort测试需要按三个步骤执行：</p>
<p>1.用TeraGen生成1GB的随机数据，并输入到目录/examples/terasort- input</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop-examples-0.20.2-cdh3u3.jar teragen \</span><br><span class="line">    10000000&#x2F;examples&#x2F;terasort- input</span><br></pre></td></tr></table></figure>
<p>2.输入数据运行TeraSort对数据进行排序，并将结果输出到目录：examples/terasort- output</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop-examples-0.20.2-cdh3u3.jar terasort \</span><br><span class="line">    examples&#x2F;terasort- input&#x2F;examples&#x2F;terasort- output</span><br></pre></td></tr></table></figure>
<p>3.用TeraValidate验证排好序的输出数据，如果有问题，将乱序的Key输出到目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar $HADOOP_HOME&#x2F;hadoop-examples-0.20.2-cdh3u3.jar teravalidate \                            </span><br><span class="line">      examples&#x2F;terasort- input&#x2F;examples&#x2F;terasort- validate</span><br></pre></td></tr></table></figure>
<p>5.微基准测试</p>
<p>用hadoop对sort greo,wordcount进行微基准测试实例，包括数据生成和测试执行两步骤。</p>
<p>6.关系查询</p>
<p>针对数据库中的相关信息进行，基准测试主要包括：装载数据、查询准备和执行查询三个步骤。</p>
<p>7.HBase</p>
<p>HBase自带的测试主要步骤</p>
<p>1）环境配置<br>2）测试<br>3）Bulk load对HBase测试</p>
<h2 id="三-大数据智能算法及测评技术"><a href="#三-大数据智能算法及测评技术" class="headerlink" title="三.大数据智能算法及测评技术"></a>三.大数据智能算法及测评技术</h2><h4 id="3-1概述"><a href="#3-1概述" class="headerlink" title="3.1概述"></a>3.1概述</h4><p>大数据基础算法：</p>
<p>聚类算法与评估：层次聚类、流聚类、K-均值。</p>
<p>分类算法与评估：朴素贝叶斯、支持向量机、K近邻</p>
<p>大数据应用算法：</p>
<p>推荐系统算法与评估：用户聚类、物品聚类、用户行为分类、推荐算法</p>
<h4 id="3-2聚类算法及测评"><a href="#3-2聚类算法及测评" class="headerlink" title="3.2聚类算法及测评"></a>3.2聚类算法及测评</h4><p>聚类的目的是在海量或难以理解的数据集中发现层次和规律，或让数据集更容易被理解，属于无监督机器学习算法。</p>
<h5 id="聚类的典型算法及分析"><a href="#聚类的典型算法及分析" class="headerlink" title="聚类的典型算法及分析"></a>聚类的典型算法及分析</h5><p>1.层次聚类法</p>
<p>1）首先开始将每个点视为簇</p>
<p>2）找出所有簇中距离最近的两个簇</p>
<p>3）合并成为一个新的簇</p>
<p>4）重复步骤</p>
<p>算法思想非常简单，仅可适用于规模相对较小的数据集。</p>
<p>2.K-均值聚类算法</p>
<p>1）首先选择K个点，称为聚类质心</p>
<p>2）遍历数据集中的每个点，按照距离K个质心的距离，将其与距离最近的质心关联起来，与同一质心相关联的所有点聚成一类。</p>
<p>3）计算每一类中所有点位置的均值，将该类的质心移动到新质心的位置。</p>
<p>4）重复上述步骤。</p>
<p>3.并行化聚类法<br>将聚类算法部署在MapReduce框架中能够大大提高算法的并行程度。</p>
<p>K-均值算法目前已经在Apache的开源机器学习软件库中已经实现。</p>
<h5 id="聚类算法的测试与评估"><a href="#聚类算法的测试与评估" class="headerlink" title="聚类算法的测试与评估"></a>聚类算法的测试与评估</h5><p>略</p>
<h4 id="3-3分类算法及评估"><a href="#3-3分类算法及评估" class="headerlink" title="3.3分类算法及评估"></a>3.3分类算法及评估</h4><p>有监督的机器学习</p>
<p>朴素贝叶斯分类算法</p>
<p>支持向量机算法 ：数据集总体上是线性可分的。对于线性不可分的情况，支持向量机的核心思想是将输入数据的特征向量映射到高维的特征向量空间，并在该特征空间中构造最优的分类面，这种方法称为核技巧。</p>
<p>并行化分类算法</p>
<p>分类算法的测试（略）</p>
<p>分类器性能的评估（略）</p>
<h4 id="3-4推荐系统算法及其测评"><a href="#3-4推荐系统算法及其测评" class="headerlink" title="3.4推荐系统算法及其测评"></a>3.4推荐系统算法及其测评</h4><p>一个完整的推荐系统主要由四个核心模块组成：用户特征的收集模块、用户行为的建模与分析模块、物品的排序与推荐模块、推荐系统的评估模块。</p>
<p>1）基于内容的推荐算法</p>
<p>根据物品的特征来计算物品与物品之间的相似度  。</p>
<p>2）基于用户的协同过滤推荐</p>
<p>一个用户会喜欢和他有相似偏好的用户喜欢的物品。计算用户的相似度，找到与目标用户偏好相似的用户集合。在这个用户集合中分析并找出目标用户可能喜欢，并且没有听说过的物品推荐给用户。</p>
<p>3）基于物品的协同过滤推荐</p>
<p>一个用户会喜欢和他之前喜欢的物品类似的物品。<br>计算物品之间的相似度。根据物品之间的相似度和用户的历史行为给用户推荐他们可能感兴趣的物品。</p>
<p>推荐系统的测评实现（略）</p>
<p>推荐系统评估（略）</p>
<h2 id="四-大数据应用的性能测试技术"><a href="#四-大数据应用的性能测试技术" class="headerlink" title="四.大数据应用的性能测试技术"></a>四.大数据应用的性能测试技术</h2><p>性能测试包括并发测试、负载测试、压力测试和容量测试。</p>
<p>1.应用性能指标：</p>
<p>呈现时间、数据传输时间、系统处理时间。<br>性能度量数据包括：<br>响应时间、用户数、吞吐量。</p>
<p>2.监控指标：</p>
<p> 用户监控、在某段时间内在线人数监控、页面访问次数等等。<br> 大数据的数据结构特点：</p>
<h4 id="4-1大数据应用的性能测评模型"><a href="#4-1大数据应用的性能测评模型" class="headerlink" title="4.1大数据应用的性能测评模型"></a>4.1大数据应用的性能测评模型</h4><h5 id="4-1-1应用负载模型"><a href="#4-1-1应用负载模型" class="headerlink" title="4.1.1应用负载模型"></a>4.1.1应用负载模型</h5><p>略</p>
<h5 id="4-1-2数据负载模型"><a href="#4-1-2数据负载模型" class="headerlink" title="4.1.2数据负载模型"></a>4.1.2数据负载模型</h5><p>性能测试流程：<br>需求分析、测试方案、测试设计、测试开发、环境准备、测试执行、结果汇总、分析调优。结构化数据、非结构化数据、半结构化数据。</p>
<h2 id="五-大数据应用的安全测评技术"><a href="#五-大数据应用的安全测评技术" class="headerlink" title="五.大数据应用的安全测评技术"></a>五.大数据应用的安全测评技术</h2><h4 id="5-1影响架构安全的因素"><a href="#5-1影响架构安全的因素" class="headerlink" title="5.1影响架构安全的因素"></a>5.1影响架构安全的因素</h4><h5 id="1）分布式计算框架安全"><a href="#1）分布式计算框架安全" class="headerlink" title="1）分布式计算框架安全"></a>1）分布式计算框架安全</h5><p>MapReduce是常用的分布式计算框架，由map和reduce两个函数组成。map函数主要负责读入输入数据，把它分成可以用相同方法解决的小数据块，然后把这些小数据块分发到不同的节点上，每一个工作节点做同样的事，再把处理的结果返回reduce函数。reduce函数把所有结果组合输出。所以map和reduce都是并行运行的，从而能够处理一般服务器不能处理的大数据量处理问题。</p>
<p>实际存在许多不安全因素：</p>
<p>1.不可信的Map函数</p>
<p>2.缺乏用户及服务器安全认证机制和访问控制机制</p>
<p>3.缺乏传输以及存储加密</p>
<h5 id="2）非关系型数据存储安全"><a href="#2）非关系型数据存储安全" class="headerlink" title="2）非关系型数据存储安全"></a>2）非关系型数据存储安全</h5><p>NoSQL是一种非关系型数据库。</p>
<p>1.薄弱的验证机制</p>
<p>2.低效的鉴权机制</p>
<p>3.NoSQL易受各类注入攻击</p>
<p>4.事务处理的一致性较弱</p>
<h4 id="5-2影响数据安全的要素"><a href="#5-2影响数据安全的要素" class="headerlink" title="5.2影响数据安全的要素"></a>5.2影响数据安全的要素</h4><h5 id="1）数据来源的可靠性"><a href="#1）数据来源的可靠性" class="headerlink" title="1）数据来源的可靠性"></a>1）数据来源的可靠性</h5><p>1.伪造或刻意制造的数据</p>
<p>2.数据在传播过程中的逐步失真或被人为破坏</p>
<p>3.元数据可能被伪造和修改</p>
<h5 id="2）数据泄露"><a href="#2）数据泄露" class="headerlink" title="2）数据泄露"></a>2）数据泄露</h5><p>略</p>
<h5 id="3）数据挖掘和分析中的隐私问题"><a href="#3）数据挖掘和分析中的隐私问题" class="headerlink" title="3）数据挖掘和分析中的隐私问题"></a>3）数据挖掘和分析中的隐私问题</h5><p>略</p>
<h4 id="5-3大数据架构的安全测评"><a href="#5-3大数据架构的安全测评" class="headerlink" title="5.3大数据架构的安全测评"></a>5.3大数据架构的安全测评</h4><h5 id="分布式计算框架的安全测评"><a href="#分布式计算框架的安全测评" class="headerlink" title="分布式计算框架的安全测评"></a>分布式计算框架的安全测评</h5><p>在用户使用mapreduce框架中常出现的危险类型有以下几种：</p>
<p>1.一个故障的map工作节点产生了错误结果，使得最终的数据分析结论不符合事实。</p>
<p>2.黑客利用自己伪造的map函数对云架构实施攻击。</p>
<p>3.一个伪造的Map节点被加入集群中，发生大量重复数据，并不断引入新的伪造map节点，对数据分析产生影响。</p>
<p>针对以上所述的危险，需要从两个维度上保证mapreduce的安全；确保mapper的可信度和确保数据的可信性。确保mapper的可信度可以从建立信任来实现。建立信任包括两个步骤：一是建立初始行信任；二是在初始认证后，周期性检查每个worker节点的安全属性和与预先确定的安全策略是否一致。</p>
<p>确保数据可信度可以通过访问控制来实现。</p>
<p>hadoop提供了两种安全机制：simple和Kerberos</p>
<p>下面以Hadoop中的安全配置为例，说明mapreduce的安全测评过程<br>。</p>
<p>1.检查身份认证和授权配置</p>
<p>2.检查调度器配置</p>
<p>3.检查作业队列权限配置</p>
<p>4.检查DFS permission配置</p>
<h5 id="非关系型数据库的安全测评"><a href="#非关系型数据库的安全测评" class="headerlink" title="非关系型数据库的安全测评"></a>非关系型数据库的安全测评</h5><p>针对NoSQL数据库，HBase</p>
<p>1.检查身份认证配置</p>
<p>2.检查接口调用的安全配置</p>
<p>3.检查访问控制</p>
<h4 id="5-4-数据的安全测评"><a href="#5-4-数据的安全测评" class="headerlink" title="5.4 数据的安全测评"></a>5.4 数据的安全测评</h4><h5 id="5-4-1数据来源的安全测评"><a href="#5-4-1数据来源的安全测评" class="headerlink" title="5.4.1数据来源的安全测评"></a>5.4.1数据来源的安全测评</h5><p>1.恶意数据输入的预防机制及其测评</p>
<p>2.基于数据源技术的数据可信度评估</p>
<h5 id="5-4-2隐私保护程度的测评"><a href="#5-4-2隐私保护程度的测评" class="headerlink" title="5.4.2隐私保护程度的测评"></a>5.4.2隐私保护程度的测评</h5><p>1.数据去隐私处理效果的测评</p>
<p>2.访问控制机制的测评</p>
<p>3.对计算结果隐私程度的测评</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/26/LSTM-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="anne's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/26/LSTM-1/" class="post-title-link" itemprop="url">LSTM.1</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-26 13:04:08 / 修改时间：13:05:02" itemprop="dateCreated datePublished" datetime="2020-01-26T13:04:08+08:00">2020-01-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="用LSTM做时间序列测试的一个例子"><a href="#用LSTM做时间序列测试的一个例子" class="headerlink" title="用LSTM做时间序列测试的一个例子"></a>用LSTM做时间序列测试的一个例子</h2><h4 id="问题：航班乘客预测"><a href="#问题：航班乘客预测" class="headerlink" title="问题：航班乘客预测"></a>问题：航班乘客预测</h4><h4 id="数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000"><a href="#数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000" class="headerlink" title="数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000"></a>数据：1949到1960一共12年，每年12个月的数据，一共144个数据，单位是1000</h4><h4 id="目标：预测国际航班未来一个月的乘客数"><a href="#目标：预测国际航班未来一个月的乘客数" class="headerlink" title="目标：预测国际航班未来一个月的乘客数"></a>目标：预测国际航班未来一个月的乘客数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from pandas import read_csv</span><br><span class="line">import math</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers import Dense</span><br><span class="line">from keras.layers import LSTM</span><br><span class="line">from sklearn.preprocessing  import MinMaxScaler</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br></pre></td></tr></table></figure>
<h6 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataframe&#x3D;read_csv(&#39;international-airline-passengers.csv&#39;,usecols&#x3D;[1],engine&#x3D;&#39;python&#39;,skipfooter&#x3D;3)</span><br><span class="line">dataset&#x3D;dataframe.values #取y轴</span><br><span class="line">#将整形变为float</span><br><span class="line">dataset&#x3D;dataset.astype(&#39;float32&#39;)</span><br><span class="line">plt.plot(dataset)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h6 id="需要把数据转换一下"><a href="#需要把数据转换一下" class="headerlink" title="需要把数据转换一下"></a>需要把数据转换一下</h6><h6 id="将一列变为两列，第一列是t月的乘客数，第二列是t-1月的乘客数。look-back是预测下一步所需要的time-steps"><a href="#将一列变为两列，第一列是t月的乘客数，第二列是t-1月的乘客数。look-back是预测下一步所需要的time-steps" class="headerlink" title="将一列变为两列，第一列是t月的乘客数，第二列是t+1月的乘客数。look_back是预测下一步所需要的time_steps"></a>将一列变为两列，第一列是t月的乘客数，第二列是t+1月的乘客数。look_back是预测下一步所需要的time_steps</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def create_dataset(dataset,look_back&#x3D;1):</span><br><span class="line">    datax,datay&#x3D;[],[]</span><br><span class="line">    for i in range(len(dataset)-look_back-1):</span><br><span class="line">         a&#x3D;dataset[i:(i+look_back),0]</span><br><span class="line">         datax.append(a)</span><br><span class="line">         datay.append(dataset[i+look_back,0])</span><br><span class="line">    return numpy.array(datax),numpy.array(datay)</span><br><span class="line">#datax是输入数据，datay是对应的输出数据</span><br><span class="line">numpy.random.seed(7)</span><br></pre></td></tr></table></figure>
<h6 id="当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感"><a href="#当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感" class="headerlink" title="当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感"></a>当激活函数为sigmoid或者tanh时，要把数据正则化，此时LSTM比较敏感</h6><h6 id="设定67-是训练数据，余下是测试数据"><a href="#设定67-是训练数据，余下是测试数据" class="headerlink" title="设定67%是训练数据，余下是测试数据"></a>设定67%是训练数据，余下是测试数据</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#正则化数据</span><br><span class="line">scaler&#x3D;MinMaxScaler(feature_range&#x3D;(0,1))</span><br><span class="line">dataset&#x3D;scaler.fit_transform(dataset)</span><br><span class="line">#分成训练数据和测试数据,即训练集和测试集是同一个时间序列的不同部分</span><br><span class="line">train_size&#x3D;int(len(dataset)*0.67)</span><br><span class="line">test_size&#x3D;len(dataset)-train_size</span><br><span class="line">train,test&#x3D;dataset[0:train_size,:],dataset[train_size:len(dataset),:]</span><br></pre></td></tr></table></figure>
<h6 id="输入为X-t时，输出为Y-t-1时的数据，此时look-back为1"><a href="#输入为X-t时，输出为Y-t-1时的数据，此时look-back为1" class="headerlink" title="输入为X=t时，输出为Y=t+1时的数据，此时look_back为1"></a>输入为X=t时，输出为Y=t+1时的数据，此时look_back为1</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">look_back&#x3D;1</span><br><span class="line">#此时trainx和testx的维度为[samples,features]</span><br><span class="line">trainx,trainy&#x3D;create_dataset(train,look_back)</span><br><span class="line">testx,testy&#x3D;creat_dataset(test,look_back)</span><br></pre></td></tr></table></figure>
<h6 id="由于投入LSTM的X需要这样的结构：-samples-look-back-features-所以交换一下"><a href="#由于投入LSTM的X需要这样的结构：-samples-look-back-features-所以交换一下" class="headerlink" title="由于投入LSTM的X需要这样的结构：[samples,look_back,features],所以交换一下"></a>由于投入LSTM的X需要这样的结构：[samples,look_back,features],所以交换一下</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainx&#x3D;numpy.reshape(trainx,(trainx.shape[0],1,trainx.shape[1]))</span><br><span class="line">testx&#x3D;numpy.reshape(testx,(testx.shape[0],1,testx.shape[1]))</span><br></pre></td></tr></table></figure>
<h6 id="建立LSTM模型"><a href="#建立LSTM模型" class="headerlink" title="建立LSTM模型"></a>建立LSTM模型</h6><h6 id="输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch-size为1"><a href="#输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch-size为1" class="headerlink" title="输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch size为1"></a>输入层有一个Input，隐藏层有4个神经元，输出层就是预测一个值，激活函数用sigmoid，迭代100次，batch size为1</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model&#x3D;Sequential()</span><br><span class="line">model.add(LSTM(4,input_shape&#x3D;(1,look_back))</span><br><span class="line">model.add(Dense(1))</span><br><span class="line">model.compile(loss&#x3D;&#39;mean_squared_error&#39;,optimizer&#x3D;&#39;adam&#39;)</span><br><span class="line">model.fit(trainx,trainy,epochs&#x3D;100,batch_size&#x3D;1,verbose&#x3D;2)</span><br></pre></td></tr></table></figure>
<h6 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainpredict&#x3D;model.predict(trainx)</span><br><span class="line">trainpredict&#x3D;model.predict(testx)</span><br></pre></td></tr></table></figure>
<h6 id="计算误差之前要把预测数据转化为同一单位"><a href="#计算误差之前要把预测数据转化为同一单位" class="headerlink" title="计算误差之前要把预测数据转化为同一单位"></a>计算误差之前要把预测数据转化为同一单位</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trainpredict&#x3D;scaler.inverse_transform(trainpredict)</span><br><span class="line">trainy&#x3D;scaler.inverse_transform([trainy])</span><br><span class="line">testpredict&#x3D;scaler.inverse_transform(testpredict)</span><br><span class="line">testy&#x3D;scaler.inverse_transform([testy])</span><br></pre></td></tr></table></figure>
<h6 id="计算mean-squared-error"><a href="#计算mean-squared-error" class="headerlink" title="计算mean squared error"></a>计算mean squared error</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trainscore&#x3D;math.sqrt(mean_squared_error(trainy[0],trainpredict[:,0&#125;))</span><br><span class="line">print(&#39;train score:%.2f RMSE&#39;%(trainscore))</span><br><span class="line">testscore&#x3D;math.sqrt(mean_squared_error(testy[0],testpredict[:,0]))</span><br><span class="line">print(&#39;test score:%.2f RMSE&#39;%(testscore))</span><br></pre></td></tr></table></figure>
<h6 id="画出结果"><a href="#画出结果" class="headerlink" title="画出结果"></a>画出结果</h6><h6 id="蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值"><a href="#蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值" class="headerlink" title="蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值"></a>蓝色为原数据，绿色为训练集的预测值，红色为测试集的预测值</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">trainpredictplot &#x3D; numpy.empty_like(dataset)</span><br><span class="line">trainpredictplot[:,:]&#x3D;numpy.nan</span><br><span class="line">trainpredictplot[look_back:len(trainpredict)+look_back,:]&#x3D;trainpredict</span><br><span class="line"></span><br><span class="line">testpredictplot&#x3D;numpy.empty_like(dataset)</span><br><span class="line">testpredictplot[:,:]&#x3D;numpy.nan</span><br><span class="line">testpredictplot[len(trainpredict)+(look_back*2)+1:len(dataset)-1,:]&#x3D;testpredict</span><br><span class="line"></span><br><span class="line">plt.plot(scaler.inverse_transform(dataset))</span><br><span class="line">plt.plot(trainpredictplot)</span><br><span class="line">plt.plot(testpredictplot)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://annen-stack.github.io/2020/01/23/newpapername/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ah">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="anne's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/23/newpapername/" class="post-title-link" itemprop="url">newpapername</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-01-23 11:50:16 / 修改时间：11:50:17" itemprop="dateCreated datePublished" datetime="2020-01-23T11:50:16+08:00">2020-01-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ah</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ah</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
